{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90adb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import deque\n",
    "#from multiprocessing import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from numpy import savetxt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb42eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../assignment 3/data/q2_dataset.csv' ,sep=r'\\s*,\\s*', header=0, encoding='ascii', engine='python')\n",
    "df = df[::-1].reset_index(drop=True)\n",
    "\n",
    "data = df.iloc[:,1:]\n",
    "data['target'] = data['Open'].shift(-1)\n",
    "\n",
    "feature_columns = ['Volume', 'Open', 'High', 'Low']\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d393fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data\n",
    "sequence_data = []\n",
    "sequences = deque(maxlen = 3)\n",
    "for entry, target in zip(data[feature_columns].values, data['target'].values):\n",
    "    sequences.append(entry)\n",
    "    if len(sequences) == 3:\n",
    "        sequence_data.append([np.array(sequences), target])\n",
    "\n",
    "X, y = [], []\n",
    "for seq, tar in sequence_data:\n",
    "    X.append(seq)\n",
    "    y.append(tar)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "X=X.reshape(1256,12)\n",
    "y = y.reshape(1256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ffd5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "train_data_RNN = np.concatenate((X_train, y_train), axis=1)\n",
    "test_data_RNN = np.concatenate((X_test, y_test), axis=1)\n",
    "\n",
    "\n",
    "savetxt('../assignment 3/data/train_data_RNN.csv', train_data_RNN, delimiter=',')\n",
    "savetxt('../assignment 3/data/test_data_RNN.csv', test_data_RNN, delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a864b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loading the train data\n",
    "\n",
    "df = np.genfromtxt('../assignment 3/data/train_data_RNN.csv',delimiter=',')\n",
    "y_train = df[:, -1].reshape(879,1)\n",
    "X_train =  df[:, :-1]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_train = X_train.reshape(879, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81cc7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, None, 512)         532480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               328192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 860,801\n",
      "Trainable params: 860,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(None, 3)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer='adam')\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df22071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x17bc74670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x17bc74670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 22:25:18.550497: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-17 22:25:18.550780: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 174.8828WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x17d6ef700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x17d6ef700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 174.6726 - val_loss: 153.1445\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 1\n",
    "training = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03fd3b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Close/Last', 'Volume', 'Open', 'High', 'Low']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = np.genfromtxt('./data/test_data_RNN.csv',delimiter=',')\n",
    "y_test = df[:, -1].reshape(377,1)\n",
    "X_test =  df[:, :-1]\n",
    "\n",
    " # 3. Run prediction on the test data and output required plot and loss\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "X_test = X_test.reshape(377, 4, 3)\n",
    "\n",
    "\n",
    "mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Loss =\", mae)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(y_test, c='k')\n",
    "plt.plot(y_pred, c='c')\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend([\"Actual P\", \"Predicted Price\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "385bcebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>$120.07</td>\n",
       "      <td>78291510</td>\n",
       "      <td>123.85</td>\n",
       "      <td>124.06</td>\n",
       "      <td>119.22</td>\n",
       "      <td>123.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>$123.28</td>\n",
       "      <td>61292800</td>\n",
       "      <td>121.94</td>\n",
       "      <td>123.85</td>\n",
       "      <td>121.21</td>\n",
       "      <td>121.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>$125.66</td>\n",
       "      <td>41365600</td>\n",
       "      <td>125.03</td>\n",
       "      <td>125.76</td>\n",
       "      <td>124.32</td>\n",
       "      <td>125.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>$125.61</td>\n",
       "      <td>31695870</td>\n",
       "      <td>126.04</td>\n",
       "      <td>126.37</td>\n",
       "      <td>125.04</td>\n",
       "      <td>126.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>$126.82</td>\n",
       "      <td>33559770</td>\n",
       "      <td>125.72</td>\n",
       "      <td>127.15</td>\n",
       "      <td>125.58</td>\n",
       "      <td>125.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Close/Last    Volume    Open    High     Low  target\n",
       "1258 2015-07-09    $120.07  78291510  123.85  124.06  119.22  123.85\n",
       "1257 2015-07-10    $123.28  61292800  121.94  123.85  121.21  121.94\n",
       "1256 2015-07-13    $125.66  41365600  125.03  125.76  124.32  125.03\n",
       "1255 2015-07-14    $125.61  31695870  126.04  126.37  125.04  126.04\n",
       "1254 2015-07-15    $126.82  33559770  125.72  127.15  125.58  125.72"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target']= data['Open']\n",
    "data['Date'] =pd.to_datetime(data.Date)\n",
    "data=data.sort_values(by='Date')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a2ebe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(data[\"Open\"])\n",
    "plt.plot(data[\"High\"])\n",
    "plt.plot(data[\"Low\"])\n",
    "#plt.plot(data[\"Close\"])\n",
    "plt.title('Stock price history')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.xlabel('Days')\n",
    "plt.legend(['Open','High','Low'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8113354d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(data[\"Volume\"])\n",
    "plt.title('Stock volume history')\n",
    "plt.ylabel('Volume')\n",
    "plt.xlabel('Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f6bf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# defining function for plotting correlation heatmap\n",
    "def plot_heatmap(correlation):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    ax = sns.heatmap(correlation,annot=True,fmt='.3f',linewidths=0.3,annot_kws={\"size\": 18})\n",
    "    plt.xticks(fontsize=12) \n",
    "    plt.yticks(fontsize=12) \n",
    "    plt.title('Correlation between features', fontsize=20)\n",
    "    ax.figure.axes[-1].tick_params(labelsize=18) # To increase fontsize of colorbar ticks\n",
    "    lim = len(correlation.columns)\n",
    "    ax.set_ylim([0,lim]) # to make the map display correctly without trimming the edges\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "638164b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec756b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>target</th>\n",
       "      <th>Volume_t-3</th>\n",
       "      <th>Volume_t-2</th>\n",
       "      <th>Volume_t-1</th>\n",
       "      <th>Open_t-3</th>\n",
       "      <th>Open_t-2</th>\n",
       "      <th>Open_t-1</th>\n",
       "      <th>High_t-3</th>\n",
       "      <th>High_t-2</th>\n",
       "      <th>High_t-1</th>\n",
       "      <th>Low_t-3</th>\n",
       "      <th>Low_t-2</th>\n",
       "      <th>Low_t-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>$120.07</td>\n",
       "      <td>78291510</td>\n",
       "      <td>123.85</td>\n",
       "      <td>124.06</td>\n",
       "      <td>119.22</td>\n",
       "      <td>123.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>$123.28</td>\n",
       "      <td>61292800</td>\n",
       "      <td>121.94</td>\n",
       "      <td>123.85</td>\n",
       "      <td>121.21</td>\n",
       "      <td>121.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78291510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>$125.66</td>\n",
       "      <td>41365600</td>\n",
       "      <td>125.03</td>\n",
       "      <td>125.76</td>\n",
       "      <td>124.32</td>\n",
       "      <td>125.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78291510.0</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.85</td>\n",
       "      <td>121.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.06</td>\n",
       "      <td>123.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.22</td>\n",
       "      <td>121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>$125.61</td>\n",
       "      <td>31695870</td>\n",
       "      <td>126.04</td>\n",
       "      <td>126.37</td>\n",
       "      <td>125.04</td>\n",
       "      <td>126.04</td>\n",
       "      <td>78291510.0</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>123.85</td>\n",
       "      <td>121.94</td>\n",
       "      <td>125.03</td>\n",
       "      <td>124.06</td>\n",
       "      <td>123.85</td>\n",
       "      <td>125.76</td>\n",
       "      <td>119.22</td>\n",
       "      <td>121.21</td>\n",
       "      <td>124.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>$126.82</td>\n",
       "      <td>33559770</td>\n",
       "      <td>125.72</td>\n",
       "      <td>127.15</td>\n",
       "      <td>125.58</td>\n",
       "      <td>125.72</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>31695870.0</td>\n",
       "      <td>121.94</td>\n",
       "      <td>125.03</td>\n",
       "      <td>126.04</td>\n",
       "      <td>123.85</td>\n",
       "      <td>125.76</td>\n",
       "      <td>126.37</td>\n",
       "      <td>121.21</td>\n",
       "      <td>124.32</td>\n",
       "      <td>125.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Close/Last    Volume    Open    High     Low  target  \\\n",
       "1258 2015-07-09    $120.07  78291510  123.85  124.06  119.22  123.85   \n",
       "1257 2015-07-10    $123.28  61292800  121.94  123.85  121.21  121.94   \n",
       "1256 2015-07-13    $125.66  41365600  125.03  125.76  124.32  125.03   \n",
       "1255 2015-07-14    $125.61  31695870  126.04  126.37  125.04  126.04   \n",
       "1254 2015-07-15    $126.82  33559770  125.72  127.15  125.58  125.72   \n",
       "\n",
       "      Volume_t-3  Volume_t-2  Volume_t-1  Open_t-3  Open_t-2  Open_t-1  \\\n",
       "1258         NaN         NaN         NaN       NaN       NaN       NaN   \n",
       "1257         NaN         NaN  78291510.0       NaN       NaN    123.85   \n",
       "1256         NaN  78291510.0  61292800.0       NaN    123.85    121.94   \n",
       "1255  78291510.0  61292800.0  41365600.0    123.85    121.94    125.03   \n",
       "1254  61292800.0  41365600.0  31695870.0    121.94    125.03    126.04   \n",
       "\n",
       "      High_t-3  High_t-2  High_t-1  Low_t-3  Low_t-2  Low_t-1  \n",
       "1258       NaN       NaN       NaN      NaN      NaN      NaN  \n",
       "1257       NaN       NaN    124.06      NaN      NaN   119.22  \n",
       "1256       NaN    124.06    123.85      NaN   119.22   121.21  \n",
       "1255    124.06    123.85    125.76   119.22   121.21   124.32  \n",
       "1254    123.85    125.76    126.37   121.21   124.32   125.04  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create features using columns from previous 3 days\n",
    "data['Volume_t-3'] = data.shift(3)['Volume']\n",
    "data['Volume_t-2'] = data.shift(2)['Volume']\n",
    "data['Volume_t-1'] = data.shift(1)['Volume']\n",
    "data['Open_t-3'] = data.shift(3)['Open']\n",
    "data['Open_t-2'] = data.shift(2)['Open']\n",
    "data['Open_t-1'] = data.shift(1)['Open']\n",
    "data['High_t-3'] = data.shift(3)['High']\n",
    "data['High_t-2'] = data.shift(2)['High']\n",
    "data['High_t-1'] = data.shift(1)['High']\n",
    "data['Low_t-3'] = data.shift(3)['Low']\n",
    "data['Low_t-2'] = data.shift(2)['Low']\n",
    "data['Low_t-1'] = data.shift(1)['Low']\n",
    "data['target']= data['Open']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afca8ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>Volume_t-3</th>\n",
       "      <th>Volume_t-2</th>\n",
       "      <th>Volume_t-1</th>\n",
       "      <th>Open_t-3</th>\n",
       "      <th>Open_t-2</th>\n",
       "      <th>Open_t-1</th>\n",
       "      <th>High_t-3</th>\n",
       "      <th>High_t-2</th>\n",
       "      <th>High_t-1</th>\n",
       "      <th>Low_t-3</th>\n",
       "      <th>Low_t-2</th>\n",
       "      <th>Low_t-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>123.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>121.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78291510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>125.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78291510.0</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.85</td>\n",
       "      <td>121.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.06</td>\n",
       "      <td>123.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.22</td>\n",
       "      <td>121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>126.04</td>\n",
       "      <td>78291510.0</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>123.85</td>\n",
       "      <td>121.94</td>\n",
       "      <td>125.03</td>\n",
       "      <td>124.06</td>\n",
       "      <td>123.85</td>\n",
       "      <td>125.76</td>\n",
       "      <td>119.22</td>\n",
       "      <td>121.21</td>\n",
       "      <td>124.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>125.72</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>31695870.0</td>\n",
       "      <td>121.94</td>\n",
       "      <td>125.03</td>\n",
       "      <td>126.04</td>\n",
       "      <td>123.85</td>\n",
       "      <td>125.76</td>\n",
       "      <td>126.37</td>\n",
       "      <td>121.21</td>\n",
       "      <td>124.32</td>\n",
       "      <td>125.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  target  Volume_t-3  Volume_t-2  Volume_t-1  Open_t-3  \\\n",
       "1258 2015-07-09  123.85         NaN         NaN         NaN       NaN   \n",
       "1257 2015-07-10  121.94         NaN         NaN  78291510.0       NaN   \n",
       "1256 2015-07-13  125.03         NaN  78291510.0  61292800.0       NaN   \n",
       "1255 2015-07-14  126.04  78291510.0  61292800.0  41365600.0    123.85   \n",
       "1254 2015-07-15  125.72  61292800.0  41365600.0  31695870.0    121.94   \n",
       "\n",
       "      Open_t-2  Open_t-1  High_t-3  High_t-2  High_t-1  Low_t-3  Low_t-2  \\\n",
       "1258       NaN       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "1257       NaN    123.85       NaN       NaN    124.06      NaN      NaN   \n",
       "1256    123.85    121.94       NaN    124.06    123.85      NaN   119.22   \n",
       "1255    121.94    125.03    124.06    123.85    125.76   119.22   121.21   \n",
       "1254    125.03    126.04    123.85    125.76    126.37   121.21   124.32   \n",
       "\n",
       "      Low_t-1  \n",
       "1258      NaN  \n",
       "1257   119.22  \n",
       "1256   121.21  \n",
       "1255   124.32  \n",
       "1254   125.04  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Close/Last','Volume','Open','High','Low'], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a5894a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          0\n",
       "target        0\n",
       "Volume_t-3    3\n",
       "Volume_t-2    2\n",
       "Volume_t-1    1\n",
       "Open_t-3      3\n",
       "Open_t-2      2\n",
       "Open_t-1      1\n",
       "High_t-3      3\n",
       "High_t-2      2\n",
       "High_t-1      1\n",
       "Low_t-3       3\n",
       "Low_t-2       2\n",
       "Low_t-1       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfa4e10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>Volume_t-3</th>\n",
       "      <th>Volume_t-2</th>\n",
       "      <th>Volume_t-1</th>\n",
       "      <th>Open_t-3</th>\n",
       "      <th>Open_t-2</th>\n",
       "      <th>Open_t-1</th>\n",
       "      <th>High_t-3</th>\n",
       "      <th>High_t-2</th>\n",
       "      <th>High_t-1</th>\n",
       "      <th>Low_t-3</th>\n",
       "      <th>Low_t-2</th>\n",
       "      <th>Low_t-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>126.04</td>\n",
       "      <td>78291510.0</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>123.85</td>\n",
       "      <td>121.94</td>\n",
       "      <td>125.03</td>\n",
       "      <td>124.06</td>\n",
       "      <td>123.85</td>\n",
       "      <td>125.76</td>\n",
       "      <td>119.22</td>\n",
       "      <td>121.21</td>\n",
       "      <td>124.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>125.72</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>31695870.0</td>\n",
       "      <td>121.94</td>\n",
       "      <td>125.03</td>\n",
       "      <td>126.04</td>\n",
       "      <td>123.85</td>\n",
       "      <td>125.76</td>\n",
       "      <td>126.37</td>\n",
       "      <td>121.21</td>\n",
       "      <td>124.32</td>\n",
       "      <td>125.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2015-07-16</td>\n",
       "      <td>127.74</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>31695870.0</td>\n",
       "      <td>33559770.0</td>\n",
       "      <td>125.03</td>\n",
       "      <td>126.04</td>\n",
       "      <td>125.72</td>\n",
       "      <td>125.76</td>\n",
       "      <td>126.37</td>\n",
       "      <td>127.15</td>\n",
       "      <td>124.32</td>\n",
       "      <td>125.04</td>\n",
       "      <td>125.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>129.08</td>\n",
       "      <td>31695870.0</td>\n",
       "      <td>33559770.0</td>\n",
       "      <td>35987630.0</td>\n",
       "      <td>126.04</td>\n",
       "      <td>125.72</td>\n",
       "      <td>127.74</td>\n",
       "      <td>126.37</td>\n",
       "      <td>127.15</td>\n",
       "      <td>128.57</td>\n",
       "      <td>125.04</td>\n",
       "      <td>125.58</td>\n",
       "      <td>127.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>130.97</td>\n",
       "      <td>33559770.0</td>\n",
       "      <td>35987630.0</td>\n",
       "      <td>45970470.0</td>\n",
       "      <td>125.72</td>\n",
       "      <td>127.74</td>\n",
       "      <td>129.08</td>\n",
       "      <td>127.15</td>\n",
       "      <td>128.57</td>\n",
       "      <td>129.62</td>\n",
       "      <td>125.58</td>\n",
       "      <td>127.35</td>\n",
       "      <td>128.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  target  Volume_t-3  Volume_t-2  Volume_t-1  Open_t-3  \\\n",
       "1255 2015-07-14  126.04  78291510.0  61292800.0  41365600.0    123.85   \n",
       "1254 2015-07-15  125.72  61292800.0  41365600.0  31695870.0    121.94   \n",
       "1253 2015-07-16  127.74  41365600.0  31695870.0  33559770.0    125.03   \n",
       "1252 2015-07-17  129.08  31695870.0  33559770.0  35987630.0    126.04   \n",
       "1251 2015-07-20  130.97  33559770.0  35987630.0  45970470.0    125.72   \n",
       "\n",
       "      Open_t-2  Open_t-1  High_t-3  High_t-2  High_t-1  Low_t-3  Low_t-2  \\\n",
       "1255    121.94    125.03    124.06    123.85    125.76   119.22   121.21   \n",
       "1254    125.03    126.04    123.85    125.76    126.37   121.21   124.32   \n",
       "1253    126.04    125.72    125.76    126.37    127.15   124.32   125.04   \n",
       "1252    125.72    127.74    126.37    127.15    128.57   125.04   125.58   \n",
       "1251    127.74    129.08    127.15    128.57    129.62   125.58   127.35   \n",
       "\n",
       "      Low_t-1  \n",
       "1255   124.32  \n",
       "1254   125.04  \n",
       "1253   125.58  \n",
       "1252   127.35  \n",
       "1251   128.31  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns with null values\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c8f4861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'target',\n",
       " 'Volume_t-3',\n",
       " 'Volume_t-2',\n",
       " 'Volume_t-1',\n",
       " 'Open_t-3',\n",
       " 'Open_t-2',\n",
       " 'Open_t-1',\n",
       " 'High_t-3',\n",
       " 'High_t-2',\n",
       " 'High_t-1',\n",
       " 'Low_t-3',\n",
       " 'Low_t-2',\n",
       " 'Low_t-1']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4216a153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume_t-3</th>\n",
       "      <th>Volume_t-2</th>\n",
       "      <th>Volume_t-1</th>\n",
       "      <th>Open_t-3</th>\n",
       "      <th>Open_t-2</th>\n",
       "      <th>Open_t-1</th>\n",
       "      <th>High_t-3</th>\n",
       "      <th>High_t-2</th>\n",
       "      <th>High_t-1</th>\n",
       "      <th>Low_t-3</th>\n",
       "      <th>Low_t-2</th>\n",
       "      <th>Low_t-1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>78291510.0</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>123.85</td>\n",
       "      <td>121.94</td>\n",
       "      <td>125.03</td>\n",
       "      <td>124.06</td>\n",
       "      <td>123.85</td>\n",
       "      <td>125.76</td>\n",
       "      <td>119.22</td>\n",
       "      <td>121.21</td>\n",
       "      <td>124.32</td>\n",
       "      <td>126.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>61292800.0</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>31695870.0</td>\n",
       "      <td>121.94</td>\n",
       "      <td>125.03</td>\n",
       "      <td>126.04</td>\n",
       "      <td>123.85</td>\n",
       "      <td>125.76</td>\n",
       "      <td>126.37</td>\n",
       "      <td>121.21</td>\n",
       "      <td>124.32</td>\n",
       "      <td>125.04</td>\n",
       "      <td>125.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2015-07-16</td>\n",
       "      <td>41365600.0</td>\n",
       "      <td>31695870.0</td>\n",
       "      <td>33559770.0</td>\n",
       "      <td>125.03</td>\n",
       "      <td>126.04</td>\n",
       "      <td>125.72</td>\n",
       "      <td>125.76</td>\n",
       "      <td>126.37</td>\n",
       "      <td>127.15</td>\n",
       "      <td>124.32</td>\n",
       "      <td>125.04</td>\n",
       "      <td>125.58</td>\n",
       "      <td>127.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>31695870.0</td>\n",
       "      <td>33559770.0</td>\n",
       "      <td>35987630.0</td>\n",
       "      <td>126.04</td>\n",
       "      <td>125.72</td>\n",
       "      <td>127.74</td>\n",
       "      <td>126.37</td>\n",
       "      <td>127.15</td>\n",
       "      <td>128.57</td>\n",
       "      <td>125.04</td>\n",
       "      <td>125.58</td>\n",
       "      <td>127.35</td>\n",
       "      <td>129.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>33559770.0</td>\n",
       "      <td>35987630.0</td>\n",
       "      <td>45970470.0</td>\n",
       "      <td>125.72</td>\n",
       "      <td>127.74</td>\n",
       "      <td>129.08</td>\n",
       "      <td>127.15</td>\n",
       "      <td>128.57</td>\n",
       "      <td>129.62</td>\n",
       "      <td>125.58</td>\n",
       "      <td>127.35</td>\n",
       "      <td>128.31</td>\n",
       "      <td>130.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Volume_t-3  Volume_t-2  Volume_t-1  Open_t-3  Open_t-2  \\\n",
       "1255 2015-07-14  78291510.0  61292800.0  41365600.0    123.85    121.94   \n",
       "1254 2015-07-15  61292800.0  41365600.0  31695870.0    121.94    125.03   \n",
       "1253 2015-07-16  41365600.0  31695870.0  33559770.0    125.03    126.04   \n",
       "1252 2015-07-17  31695870.0  33559770.0  35987630.0    126.04    125.72   \n",
       "1251 2015-07-20  33559770.0  35987630.0  45970470.0    125.72    127.74   \n",
       "\n",
       "      Open_t-1  High_t-3  High_t-2  High_t-1  Low_t-3  Low_t-2  Low_t-1  \\\n",
       "1255    125.03    124.06    123.85    125.76   119.22   121.21   124.32   \n",
       "1254    126.04    123.85    125.76    126.37   121.21   124.32   125.04   \n",
       "1253    125.72    125.76    126.37    127.15   124.32   125.04   125.58   \n",
       "1252    127.74    126.37    127.15    128.57   125.04   125.58   127.35   \n",
       "1251    129.08    127.15    128.57    129.62   125.58   127.35   128.31   \n",
       "\n",
       "      target  \n",
       "1255  126.04  \n",
       "1254  125.72  \n",
       "1253  127.74  \n",
       "1252  129.08  \n",
       "1251  130.97  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[\n",
    " 'Date',\n",
    " 'Volume_t-3',\n",
    " 'Volume_t-2',\n",
    " 'Volume_t-1',\n",
    " 'Open_t-3',\n",
    " 'Open_t-2',\n",
    " 'Open_t-1',\n",
    " 'High_t-3',\n",
    " 'High_t-2',\n",
    " 'High_t-1',\n",
    " 'Low_t-3',\n",
    " 'Low_t-2',\n",
    " 'Low_t-1', \n",
    " 'target']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d5de9",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "\n",
    "We sorted the dataset in ascending order, since our intention is to predict the opening price from the **previous** three days. Using the pandas shift function which shifts the index by desired number of periods, we were able to create new features by specifying the index that was needed. For example, to get the Volume from three days prior, we shift by 3 - data.shift(3)['Volume']. This process was repeated for all necessary columns and indices. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb6e9892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1256"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b56025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split the data into train and test set\n",
    "train, test = train_test_split(data, test_size=0.30, random_state=0)\n",
    "#save the data\n",
    "train.to_csv('train_data_RNN.csv',index=False)\n",
    "test.to_csv('test_data_RNN.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff2ea5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "737197d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume_t-3</th>\n",
       "      <th>Volume_t-2</th>\n",
       "      <th>Volume_t-1</th>\n",
       "      <th>Open_t-3</th>\n",
       "      <th>Open_t-2</th>\n",
       "      <th>Open_t-1</th>\n",
       "      <th>High_t-3</th>\n",
       "      <th>High_t-2</th>\n",
       "      <th>High_t-1</th>\n",
       "      <th>Low_t-3</th>\n",
       "      <th>Low_t-2</th>\n",
       "      <th>Low_t-1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>34581850.0</td>\n",
       "      <td>26750260.0</td>\n",
       "      <td>34949690.0</td>\n",
       "      <td>164.88</td>\n",
       "      <td>172.58</td>\n",
       "      <td>170.97</td>\n",
       "      <td>172.01</td>\n",
       "      <td>174.23</td>\n",
       "      <td>172.48</td>\n",
       "      <td>164.77</td>\n",
       "      <td>172.08</td>\n",
       "      <td>168.20</td>\n",
       "      <td>169.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>42621540.0</td>\n",
       "      <td>35217270.0</td>\n",
       "      <td>30521720.0</td>\n",
       "      <td>307.24</td>\n",
       "      <td>310.60</td>\n",
       "      <td>311.64</td>\n",
       "      <td>310.43</td>\n",
       "      <td>312.67</td>\n",
       "      <td>317.07</td>\n",
       "      <td>306.20</td>\n",
       "      <td>308.25</td>\n",
       "      <td>311.15</td>\n",
       "      <td>316.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>28204640.0</td>\n",
       "      <td>31644240.0</td>\n",
       "      <td>23793830.0</td>\n",
       "      <td>174.65</td>\n",
       "      <td>172.40</td>\n",
       "      <td>168.99</td>\n",
       "      <td>175.57</td>\n",
       "      <td>173.94</td>\n",
       "      <td>170.66</td>\n",
       "      <td>172.85</td>\n",
       "      <td>170.34</td>\n",
       "      <td>168.42</td>\n",
       "      <td>171.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>17633730.0</td>\n",
       "      <td>21175670.0</td>\n",
       "      <td>16916650.0</td>\n",
       "      <td>156.29</td>\n",
       "      <td>156.91</td>\n",
       "      <td>157.23</td>\n",
       "      <td>157.42</td>\n",
       "      <td>157.55</td>\n",
       "      <td>157.83</td>\n",
       "      <td>156.20</td>\n",
       "      <td>155.27</td>\n",
       "      <td>156.78</td>\n",
       "      <td>159.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>21337310.0</td>\n",
       "      <td>23724430.0</td>\n",
       "      <td>26043820.0</td>\n",
       "      <td>116.74</td>\n",
       "      <td>116.80</td>\n",
       "      <td>116.35</td>\n",
       "      <td>117.50</td>\n",
       "      <td>117.40</td>\n",
       "      <td>116.51</td>\n",
       "      <td>116.68</td>\n",
       "      <td>116.78</td>\n",
       "      <td>115.64</td>\n",
       "      <td>115.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Volume_t-3  Volume_t-2  Volume_t-1  Open_t-3  Open_t-2  \\\n",
       "566 2018-04-09  34581850.0  26750260.0  34949690.0    164.88    172.58   \n",
       "121 2020-01-14  42621540.0  35217270.0  30521720.0    307.24    310.60   \n",
       "354 2019-02-11  28204640.0  31644240.0  23793830.0    174.65    172.40   \n",
       "676 2017-10-27  17633730.0  21175670.0  16916650.0    156.29    156.91   \n",
       "888 2016-12-23  21337310.0  23724430.0  26043820.0    116.74    116.80   \n",
       "\n",
       "     Open_t-1  High_t-3  High_t-2  High_t-1  Low_t-3  Low_t-2  Low_t-1  target  \n",
       "566    170.97    172.01    174.23    172.48   164.77   172.08   168.20  169.88  \n",
       "121    311.64    310.43    312.67    317.07   306.20   308.25   311.15  316.70  \n",
       "354    168.99    175.57    173.94    170.66   172.85   170.34   168.42  171.05  \n",
       "676    157.23    157.42    157.55    157.83   156.20   155.27   156.78  159.29  \n",
       "888    116.35    117.50    117.40    116.51   116.68   116.78   115.64  115.59  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4678a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train_data_RNN.csv')\n",
    "data_test = pd.read_csv('test_data_RNN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ada979",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "**Scaling the data**\n",
    "\n",
    "The range of the data is widely varied. The values of Volume are very high and could skew the model. Normalizing data helps the algorithm in converging i.e. to find local/ global minimum efficiently. We utilise the Minmax scaler to keep feature values between 0 and 1. \n",
    "\n",
    "Scaled values of X are created using the following formula:\n",
    "\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "X_scaled = X_std * (max - min) + min\n",
    "\n",
    "We also tried the Standard scaler, however there was no significant difference in training or test loss with this scaler. \n",
    "\n",
    "**Splitting Features and Target**\n",
    "\n",
    "The target is the opening price of the day we wish to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c86bba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate features and target\n",
    "X_train = data_train.drop(['Date','target'], axis = 1)\n",
    "y_train = data_train['target']\n",
    "X_test_date = data_test\n",
    "X_test = data_test.drop(['Date','target'], axis = 1)\n",
    "y_test = data_test['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bed78d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_t-3</th>\n",
       "      <th>Volume_t-2</th>\n",
       "      <th>Volume_t-1</th>\n",
       "      <th>Open_t-3</th>\n",
       "      <th>Open_t-2</th>\n",
       "      <th>Open_t-1</th>\n",
       "      <th>High_t-3</th>\n",
       "      <th>High_t-2</th>\n",
       "      <th>High_t-1</th>\n",
       "      <th>Low_t-3</th>\n",
       "      <th>Low_t-2</th>\n",
       "      <th>Low_t-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34581850.0</td>\n",
       "      <td>26750260.0</td>\n",
       "      <td>34949690.0</td>\n",
       "      <td>164.88</td>\n",
       "      <td>172.58</td>\n",
       "      <td>170.97</td>\n",
       "      <td>172.01</td>\n",
       "      <td>174.23</td>\n",
       "      <td>172.48</td>\n",
       "      <td>164.77</td>\n",
       "      <td>172.08</td>\n",
       "      <td>168.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42621540.0</td>\n",
       "      <td>35217270.0</td>\n",
       "      <td>30521720.0</td>\n",
       "      <td>307.24</td>\n",
       "      <td>310.60</td>\n",
       "      <td>311.64</td>\n",
       "      <td>310.43</td>\n",
       "      <td>312.67</td>\n",
       "      <td>317.07</td>\n",
       "      <td>306.20</td>\n",
       "      <td>308.25</td>\n",
       "      <td>311.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28204640.0</td>\n",
       "      <td>31644240.0</td>\n",
       "      <td>23793830.0</td>\n",
       "      <td>174.65</td>\n",
       "      <td>172.40</td>\n",
       "      <td>168.99</td>\n",
       "      <td>175.57</td>\n",
       "      <td>173.94</td>\n",
       "      <td>170.66</td>\n",
       "      <td>172.85</td>\n",
       "      <td>170.34</td>\n",
       "      <td>168.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17633730.0</td>\n",
       "      <td>21175670.0</td>\n",
       "      <td>16916650.0</td>\n",
       "      <td>156.29</td>\n",
       "      <td>156.91</td>\n",
       "      <td>157.23</td>\n",
       "      <td>157.42</td>\n",
       "      <td>157.55</td>\n",
       "      <td>157.83</td>\n",
       "      <td>156.20</td>\n",
       "      <td>155.27</td>\n",
       "      <td>156.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21337310.0</td>\n",
       "      <td>23724430.0</td>\n",
       "      <td>26043820.0</td>\n",
       "      <td>116.74</td>\n",
       "      <td>116.80</td>\n",
       "      <td>116.35</td>\n",
       "      <td>117.50</td>\n",
       "      <td>117.40</td>\n",
       "      <td>116.51</td>\n",
       "      <td>116.68</td>\n",
       "      <td>116.78</td>\n",
       "      <td>115.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>20182050.0</td>\n",
       "      <td>20670830.0</td>\n",
       "      <td>15955820.0</td>\n",
       "      <td>189.69</td>\n",
       "      <td>191.78</td>\n",
       "      <td>190.68</td>\n",
       "      <td>192.55</td>\n",
       "      <td>192.43</td>\n",
       "      <td>191.96</td>\n",
       "      <td>189.69</td>\n",
       "      <td>190.17</td>\n",
       "      <td>189.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>36487930.0</td>\n",
       "      <td>38016810.0</td>\n",
       "      <td>52954070.0</td>\n",
       "      <td>211.15</td>\n",
       "      <td>216.88</td>\n",
       "      <td>219.05</td>\n",
       "      <td>215.18</td>\n",
       "      <td>220.45</td>\n",
       "      <td>222.36</td>\n",
       "      <td>209.27</td>\n",
       "      <td>216.62</td>\n",
       "      <td>216.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>28803760.0</td>\n",
       "      <td>33511990.0</td>\n",
       "      <td>36486560.0</td>\n",
       "      <td>303.22</td>\n",
       "      <td>305.64</td>\n",
       "      <td>308.10</td>\n",
       "      <td>305.17</td>\n",
       "      <td>310.35</td>\n",
       "      <td>317.05</td>\n",
       "      <td>301.97</td>\n",
       "      <td>304.29</td>\n",
       "      <td>307.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>35907770.0</td>\n",
       "      <td>25402270.0</td>\n",
       "      <td>21983410.0</td>\n",
       "      <td>151.78</td>\n",
       "      <td>153.80</td>\n",
       "      <td>153.89</td>\n",
       "      <td>153.92</td>\n",
       "      <td>154.72</td>\n",
       "      <td>154.28</td>\n",
       "      <td>151.69</td>\n",
       "      <td>153.54</td>\n",
       "      <td>152.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>39824200.0</td>\n",
       "      <td>41464880.0</td>\n",
       "      <td>38116290.0</td>\n",
       "      <td>173.68</td>\n",
       "      <td>167.25</td>\n",
       "      <td>167.81</td>\n",
       "      <td>175.15</td>\n",
       "      <td>170.02</td>\n",
       "      <td>171.75</td>\n",
       "      <td>166.92</td>\n",
       "      <td>165.19</td>\n",
       "      <td>166.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>879 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Volume_t-3  Volume_t-2  Volume_t-1  Open_t-3  Open_t-2  Open_t-1  \\\n",
       "0    34581850.0  26750260.0  34949690.0    164.88    172.58    170.97   \n",
       "1    42621540.0  35217270.0  30521720.0    307.24    310.60    311.64   \n",
       "2    28204640.0  31644240.0  23793830.0    174.65    172.40    168.99   \n",
       "3    17633730.0  21175670.0  16916650.0    156.29    156.91    157.23   \n",
       "4    21337310.0  23724430.0  26043820.0    116.74    116.80    116.35   \n",
       "..          ...         ...         ...       ...       ...       ...   \n",
       "874  20182050.0  20670830.0  15955820.0    189.69    191.78    190.68   \n",
       "875  36487930.0  38016810.0  52954070.0    211.15    216.88    219.05   \n",
       "876  28803760.0  33511990.0  36486560.0    303.22    305.64    308.10   \n",
       "877  35907770.0  25402270.0  21983410.0    151.78    153.80    153.89   \n",
       "878  39824200.0  41464880.0  38116290.0    173.68    167.25    167.81   \n",
       "\n",
       "     High_t-3  High_t-2  High_t-1  Low_t-3  Low_t-2  Low_t-1  \n",
       "0      172.01    174.23    172.48   164.77   172.08   168.20  \n",
       "1      310.43    312.67    317.07   306.20   308.25   311.15  \n",
       "2      175.57    173.94    170.66   172.85   170.34   168.42  \n",
       "3      157.42    157.55    157.83   156.20   155.27   156.78  \n",
       "4      117.50    117.40    116.51   116.68   116.78   115.64  \n",
       "..        ...       ...       ...      ...      ...      ...  \n",
       "874    192.55    192.43    191.96   189.69   190.17   189.56  \n",
       "875    215.18    220.45    222.36   209.27   216.62   216.81  \n",
       "876    305.17    310.35    317.05   301.97   304.29   307.24  \n",
       "877    153.92    154.72    154.28   151.69   153.54   152.70  \n",
       "878    175.15    170.02    171.75   166.92   165.19   166.90  \n",
       "\n",
       "[879 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43b0bfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_t-3</th>\n",
       "      <th>Volume_t-2</th>\n",
       "      <th>Volume_t-1</th>\n",
       "      <th>Open_t-3</th>\n",
       "      <th>Open_t-2</th>\n",
       "      <th>Open_t-1</th>\n",
       "      <th>High_t-3</th>\n",
       "      <th>High_t-2</th>\n",
       "      <th>High_t-1</th>\n",
       "      <th>Low_t-3</th>\n",
       "      <th>Low_t-2</th>\n",
       "      <th>Low_t-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35987630.0</td>\n",
       "      <td>45970470.0</td>\n",
       "      <td>55204920.0</td>\n",
       "      <td>127.74</td>\n",
       "      <td>129.08</td>\n",
       "      <td>130.97</td>\n",
       "      <td>128.57</td>\n",
       "      <td>129.62</td>\n",
       "      <td>132.97</td>\n",
       "      <td>127.35</td>\n",
       "      <td>128.31</td>\n",
       "      <td>130.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35421310.0</td>\n",
       "      <td>25674500.0</td>\n",
       "      <td>24725210.0</td>\n",
       "      <td>145.13</td>\n",
       "      <td>147.17</td>\n",
       "      <td>145.01</td>\n",
       "      <td>147.16</td>\n",
       "      <td>148.28</td>\n",
       "      <td>146.16</td>\n",
       "      <td>145.11</td>\n",
       "      <td>145.38</td>\n",
       "      <td>143.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50278030.0</td>\n",
       "      <td>35678360.0</td>\n",
       "      <td>50061580.0</td>\n",
       "      <td>113.38</td>\n",
       "      <td>113.63</td>\n",
       "      <td>113.25</td>\n",
       "      <td>114.18</td>\n",
       "      <td>114.72</td>\n",
       "      <td>115.50</td>\n",
       "      <td>112.52</td>\n",
       "      <td>113.30</td>\n",
       "      <td>112.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29773430.0</td>\n",
       "      <td>22526310.0</td>\n",
       "      <td>30684390.0</td>\n",
       "      <td>184.28</td>\n",
       "      <td>183.08</td>\n",
       "      <td>186.51</td>\n",
       "      <td>184.99</td>\n",
       "      <td>185.47</td>\n",
       "      <td>191.92</td>\n",
       "      <td>181.14</td>\n",
       "      <td>182.15</td>\n",
       "      <td>185.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26560420.0</td>\n",
       "      <td>26178840.0</td>\n",
       "      <td>31735810.0</td>\n",
       "      <td>109.51</td>\n",
       "      <td>110.23</td>\n",
       "      <td>109.95</td>\n",
       "      <td>110.73</td>\n",
       "      <td>110.98</td>\n",
       "      <td>110.42</td>\n",
       "      <td>109.42</td>\n",
       "      <td>109.20</td>\n",
       "      <td>108.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>64678220.0</td>\n",
       "      <td>53168580.0</td>\n",
       "      <td>56157370.0</td>\n",
       "      <td>112.18</td>\n",
       "      <td>111.94</td>\n",
       "      <td>111.07</td>\n",
       "      <td>112.68</td>\n",
       "      <td>112.80</td>\n",
       "      <td>111.99</td>\n",
       "      <td>109.79</td>\n",
       "      <td>110.35</td>\n",
       "      <td>108.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>33935720.0</td>\n",
       "      <td>69281360.0</td>\n",
       "      <td>54017920.0</td>\n",
       "      <td>208.76</td>\n",
       "      <td>216.42</td>\n",
       "      <td>213.90</td>\n",
       "      <td>210.16</td>\n",
       "      <td>221.37</td>\n",
       "      <td>218.03</td>\n",
       "      <td>207.31</td>\n",
       "      <td>211.30</td>\n",
       "      <td>206.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>24833800.0</td>\n",
       "      <td>25080500.0</td>\n",
       "      <td>20117070.0</td>\n",
       "      <td>145.87</td>\n",
       "      <td>145.50</td>\n",
       "      <td>147.97</td>\n",
       "      <td>146.18</td>\n",
       "      <td>148.49</td>\n",
       "      <td>149.33</td>\n",
       "      <td>144.82</td>\n",
       "      <td>145.44</td>\n",
       "      <td>147.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>53812480.0</td>\n",
       "      <td>32503750.0</td>\n",
       "      <td>45247890.0</td>\n",
       "      <td>284.69</td>\n",
       "      <td>277.95</td>\n",
       "      <td>276.28</td>\n",
       "      <td>286.95</td>\n",
       "      <td>281.68</td>\n",
       "      <td>277.25</td>\n",
       "      <td>276.86</td>\n",
       "      <td>276.85</td>\n",
       "      <td>265.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>69032740.0</td>\n",
       "      <td>24677880.0</td>\n",
       "      <td>12119710.0</td>\n",
       "      <td>282.23</td>\n",
       "      <td>280.53</td>\n",
       "      <td>284.69</td>\n",
       "      <td>282.65</td>\n",
       "      <td>284.25</td>\n",
       "      <td>284.89</td>\n",
       "      <td>278.56</td>\n",
       "      <td>280.37</td>\n",
       "      <td>282.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Volume_t-3  Volume_t-2  Volume_t-1  Open_t-3  Open_t-2  Open_t-1  \\\n",
       "0    35987630.0  45970470.0  55204920.0    127.74    129.08    130.97   \n",
       "1    35421310.0  25674500.0  24725210.0    145.13    147.17    145.01   \n",
       "2    50278030.0  35678360.0  50061580.0    113.38    113.63    113.25   \n",
       "3    29773430.0  22526310.0  30684390.0    184.28    183.08    186.51   \n",
       "4    26560420.0  26178840.0  31735810.0    109.51    110.23    109.95   \n",
       "..          ...         ...         ...       ...       ...       ...   \n",
       "372  64678220.0  53168580.0  56157370.0    112.18    111.94    111.07   \n",
       "373  33935720.0  69281360.0  54017920.0    208.76    216.42    213.90   \n",
       "374  24833800.0  25080500.0  20117070.0    145.87    145.50    147.97   \n",
       "375  53812480.0  32503750.0  45247890.0    284.69    277.95    276.28   \n",
       "376  69032740.0  24677880.0  12119710.0    282.23    280.53    284.69   \n",
       "\n",
       "     High_t-3  High_t-2  High_t-1  Low_t-3  Low_t-2  Low_t-1  \n",
       "0      128.57    129.62    132.97   127.35   128.31   130.70  \n",
       "1      147.16    148.28    146.16   145.11   145.38   143.62  \n",
       "2      114.18    114.72    115.50   112.52   113.30   112.37  \n",
       "3      184.99    185.47    191.92   181.14   182.15   185.77  \n",
       "4      110.73    110.98    110.42   109.42   109.20   108.12  \n",
       "..        ...       ...       ...      ...      ...      ...  \n",
       "372    112.68    112.80    111.99   109.79   110.35   108.80  \n",
       "373    210.16    221.37    218.03   207.31   211.30   206.74  \n",
       "374    146.18    148.49    149.33   144.82   145.44   147.33  \n",
       "375    286.95    281.68    277.25   276.86   276.85   265.43  \n",
       "376    282.65    284.25    284.89   278.56   280.37   282.92  \n",
       "\n",
       "[377 rows x 12 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b535d6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      169.88\n",
       "1      316.70\n",
       "2      171.05\n",
       "3      159.29\n",
       "4      115.59\n",
       "        ...  \n",
       "874    192.45\n",
       "875    209.55\n",
       "876    317.83\n",
       "877    153.21\n",
       "878    167.88\n",
       "Name: target, Length: 879, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3eb969fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      132.85\n",
       "1      144.49\n",
       "2      116.44\n",
       "3      191.81\n",
       "4      108.91\n",
       "        ...  \n",
       "372    112.02\n",
       "373    205.53\n",
       "374    148.82\n",
       "375    273.61\n",
       "376    284.82\n",
       "Name: target, Length: 377, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab8c5e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume_t-3</th>\n",
       "      <th>Volume_t-2</th>\n",
       "      <th>Volume_t-1</th>\n",
       "      <th>Open_t-3</th>\n",
       "      <th>Open_t-2</th>\n",
       "      <th>Open_t-1</th>\n",
       "      <th>High_t-3</th>\n",
       "      <th>High_t-2</th>\n",
       "      <th>High_t-1</th>\n",
       "      <th>Low_t-3</th>\n",
       "      <th>Low_t-2</th>\n",
       "      <th>Low_t-1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-21</td>\n",
       "      <td>35987630.0</td>\n",
       "      <td>45970470.0</td>\n",
       "      <td>55204920.0</td>\n",
       "      <td>127.74</td>\n",
       "      <td>129.08</td>\n",
       "      <td>130.97</td>\n",
       "      <td>128.57</td>\n",
       "      <td>129.62</td>\n",
       "      <td>132.97</td>\n",
       "      <td>127.35</td>\n",
       "      <td>128.31</td>\n",
       "      <td>130.70</td>\n",
       "      <td>132.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-28</td>\n",
       "      <td>35421310.0</td>\n",
       "      <td>25674500.0</td>\n",
       "      <td>24725210.0</td>\n",
       "      <td>145.13</td>\n",
       "      <td>147.17</td>\n",
       "      <td>145.01</td>\n",
       "      <td>147.16</td>\n",
       "      <td>148.28</td>\n",
       "      <td>146.16</td>\n",
       "      <td>145.11</td>\n",
       "      <td>145.38</td>\n",
       "      <td>143.62</td>\n",
       "      <td>144.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-25</td>\n",
       "      <td>50278030.0</td>\n",
       "      <td>35678360.0</td>\n",
       "      <td>50061580.0</td>\n",
       "      <td>113.38</td>\n",
       "      <td>113.63</td>\n",
       "      <td>113.25</td>\n",
       "      <td>114.18</td>\n",
       "      <td>114.72</td>\n",
       "      <td>115.50</td>\n",
       "      <td>112.52</td>\n",
       "      <td>113.30</td>\n",
       "      <td>112.37</td>\n",
       "      <td>116.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>29773430.0</td>\n",
       "      <td>22526310.0</td>\n",
       "      <td>30684390.0</td>\n",
       "      <td>184.28</td>\n",
       "      <td>183.08</td>\n",
       "      <td>186.51</td>\n",
       "      <td>184.99</td>\n",
       "      <td>185.47</td>\n",
       "      <td>191.92</td>\n",
       "      <td>181.14</td>\n",
       "      <td>182.15</td>\n",
       "      <td>185.77</td>\n",
       "      <td>191.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>26560420.0</td>\n",
       "      <td>26178840.0</td>\n",
       "      <td>31735810.0</td>\n",
       "      <td>109.51</td>\n",
       "      <td>110.23</td>\n",
       "      <td>109.95</td>\n",
       "      <td>110.73</td>\n",
       "      <td>110.98</td>\n",
       "      <td>110.42</td>\n",
       "      <td>109.42</td>\n",
       "      <td>109.20</td>\n",
       "      <td>108.12</td>\n",
       "      <td>108.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>64678220.0</td>\n",
       "      <td>53168580.0</td>\n",
       "      <td>56157370.0</td>\n",
       "      <td>112.18</td>\n",
       "      <td>111.94</td>\n",
       "      <td>111.07</td>\n",
       "      <td>112.68</td>\n",
       "      <td>112.80</td>\n",
       "      <td>111.99</td>\n",
       "      <td>109.79</td>\n",
       "      <td>110.35</td>\n",
       "      <td>108.80</td>\n",
       "      <td>112.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>33935720.0</td>\n",
       "      <td>69281360.0</td>\n",
       "      <td>54017920.0</td>\n",
       "      <td>208.76</td>\n",
       "      <td>216.42</td>\n",
       "      <td>213.90</td>\n",
       "      <td>210.16</td>\n",
       "      <td>221.37</td>\n",
       "      <td>218.03</td>\n",
       "      <td>207.31</td>\n",
       "      <td>211.30</td>\n",
       "      <td>206.74</td>\n",
       "      <td>205.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>24833800.0</td>\n",
       "      <td>25080500.0</td>\n",
       "      <td>20117070.0</td>\n",
       "      <td>145.87</td>\n",
       "      <td>145.50</td>\n",
       "      <td>147.97</td>\n",
       "      <td>146.18</td>\n",
       "      <td>148.49</td>\n",
       "      <td>149.33</td>\n",
       "      <td>144.82</td>\n",
       "      <td>145.44</td>\n",
       "      <td>147.33</td>\n",
       "      <td>148.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>53812480.0</td>\n",
       "      <td>32503750.0</td>\n",
       "      <td>45247890.0</td>\n",
       "      <td>284.69</td>\n",
       "      <td>277.95</td>\n",
       "      <td>276.28</td>\n",
       "      <td>286.95</td>\n",
       "      <td>281.68</td>\n",
       "      <td>277.25</td>\n",
       "      <td>276.86</td>\n",
       "      <td>276.85</td>\n",
       "      <td>265.43</td>\n",
       "      <td>273.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>69032740.0</td>\n",
       "      <td>24677880.0</td>\n",
       "      <td>12119710.0</td>\n",
       "      <td>282.23</td>\n",
       "      <td>280.53</td>\n",
       "      <td>284.69</td>\n",
       "      <td>282.65</td>\n",
       "      <td>284.25</td>\n",
       "      <td>284.89</td>\n",
       "      <td>278.56</td>\n",
       "      <td>280.37</td>\n",
       "      <td>282.92</td>\n",
       "      <td>284.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Volume_t-3  Volume_t-2  Volume_t-1  Open_t-3  Open_t-2  \\\n",
       "0    2015-07-21  35987630.0  45970470.0  55204920.0    127.74    129.08   \n",
       "1    2017-06-28  35421310.0  25674500.0  24725210.0    145.13    147.17   \n",
       "2    2015-09-25  50278030.0  35678360.0  50061580.0    113.38    113.63   \n",
       "3    2019-06-10  29773430.0  22526310.0  30684390.0    184.28    183.08   \n",
       "4    2016-04-08  26560420.0  26178840.0  31735810.0    109.51    110.23   \n",
       "..          ...         ...         ...         ...       ...       ...   \n",
       "372  2015-12-17  64678220.0  53168580.0  56157370.0    112.18    111.94   \n",
       "373  2019-08-02  33935720.0  69281360.0  54017920.0    208.76    216.42   \n",
       "374  2017-07-17  24833800.0  25080500.0  20117070.0    145.87    145.50   \n",
       "375  2020-04-22  53812480.0  32503750.0  45247890.0    284.69    277.95   \n",
       "376  2019-12-26  69032740.0  24677880.0  12119710.0    282.23    280.53   \n",
       "\n",
       "     Open_t-1  High_t-3  High_t-2  High_t-1  Low_t-3  Low_t-2  Low_t-1  target  \n",
       "0      130.97    128.57    129.62    132.97   127.35   128.31   130.70  132.85  \n",
       "1      145.01    147.16    148.28    146.16   145.11   145.38   143.62  144.49  \n",
       "2      113.25    114.18    114.72    115.50   112.52   113.30   112.37  116.44  \n",
       "3      186.51    184.99    185.47    191.92   181.14   182.15   185.77  191.81  \n",
       "4      109.95    110.73    110.98    110.42   109.42   109.20   108.12  108.91  \n",
       "..        ...       ...       ...       ...      ...      ...      ...     ...  \n",
       "372    111.07    112.68    112.80    111.99   109.79   110.35   108.80  112.02  \n",
       "373    213.90    210.16    221.37    218.03   207.31   211.30   206.74  205.53  \n",
       "374    147.97    146.18    148.49    149.33   144.82   145.44   147.33  148.82  \n",
       "375    276.28    286.95    281.68    277.25   276.86   276.85   265.43  273.61  \n",
       "376    284.69    282.65    284.25    284.89   278.56   280.37   282.92  284.82  \n",
       "\n",
       "[377 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cab48e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the dataset using minmaxscaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e78f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the scaler to apply it on the test dataset\n",
    "import pickle\n",
    "with open('scaler_RNN_model','wb') as file_pick:\n",
    "    pickle.dump(scaler,file_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba44ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy array conversion\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f35ae295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f3f9a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879, 12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0],X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ae0cd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 12)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0],X_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877f83a",
   "metadata": {},
   "source": [
    "## Design Steps\n",
    "\n",
    "MODEL 1(Udacity)\n",
    "\n",
    "LSTM LAYER 1 - width of 32\n",
    "Dropout 0.2\n",
    "LSTM LAYER 2 - 16 units\n",
    "Dropout 0.2\n",
    "Dense Layer\n",
    "\n",
    "SHOW TRAINING LOSS FOR THAT AND DO THE OTHER ONE UNDER\n",
    "\n",
    "MODEL 2 (Medium)\n",
    "\n",
    "LSTM LAYER 1 - 50 units\n",
    "Dropout 0.2\n",
    "LSTM LAYER 2 - 50 units\n",
    "Dropout 0.2\n",
    "LSTM LAYER 2 - 50 units\n",
    "Dropout 0.2\n",
    "Dense Layer\n",
    "\n",
    "MODEL 3(IEEE Paper for amazon spot prediction pricing)\n",
    "\n",
    "LSTM LAYER 1 - width of 32\n",
    "Dropout 0.2\n",
    "LSTM LAYER 2 - 32 units\n",
    "Dropout 0.2\n",
    "Dense Layer\n",
    "\n",
    "TALK ABOUT ADAGRAD OPTIMIZER AND SHOW REASONS WHY IT WAS SO BAD\n",
    "\n",
    "mean_squared_error' has been used as loss function\n",
    "    Optimizer: Here adam optimizer has been used. Adam is an adaptive\n",
    "    learning rate optimization algorithm thats been designed specifically for\n",
    "    training deep neural networks.\n",
    "    Accuracy is not used as a metric because this is a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55e78f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2d5ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True, input_shape=(12,1)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(50,return_sequences=True),\n",
    "\ttf.keras.layers.Dropout(0.2),\n",
    "     tf.keras.layers.LSTM(50),\n",
    "\ttf.keras.layers.Dropout(0.2),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c7289a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2c43dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 12, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 12, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 12, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 12, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 12, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 12, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 71,051\n",
      "Trainable params: 71,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b40d872a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2a8e71280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2a8e71280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "23/27 [========================>.....] - ETA: 0s - loss: 31463.1947WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2a9546160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2a9546160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 31624.7219 - val_loss: 31784.7520\n",
      "Epoch 2/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 30314.0540 - val_loss: 30484.8301\n",
      "Epoch 3/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 28197.3568 - val_loss: 30035.7793\n",
      "Epoch 4/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 28124.6147 - val_loss: 29454.7793\n",
      "Epoch 5/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 28201.2008 - val_loss: 28867.1582\n",
      "Epoch 6/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 27859.0696 - val_loss: 28411.7734\n",
      "Epoch 7/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 28259.8872 - val_loss: 27920.7793\n",
      "Epoch 8/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 27199.1418 - val_loss: 27651.2441\n",
      "Epoch 9/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 26712.5229 - val_loss: 27015.2832\n",
      "Epoch 10/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 25929.2545 - val_loss: 26635.1641\n",
      "Epoch 11/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 24908.6995 - val_loss: 26400.6934\n",
      "Epoch 12/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 23985.7337 - val_loss: 25807.0742\n",
      "Epoch 13/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 24901.7121 - val_loss: 25277.3613\n",
      "Epoch 14/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 23547.6931 - val_loss: 25102.5547\n",
      "Epoch 15/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 23719.1523 - val_loss: 24711.4492\n",
      "Epoch 16/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 24464.4610 - val_loss: 24206.8867\n",
      "Epoch 17/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 24179.8180 - val_loss: 24043.4258\n",
      "Epoch 18/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 24174.2960 - val_loss: 23575.7812\n",
      "Epoch 19/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 21885.1490 - val_loss: 23325.9688\n",
      "Epoch 20/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 22267.0609 - val_loss: 22608.7031\n",
      "Epoch 21/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 21529.8176 - val_loss: 22421.9395\n",
      "Epoch 22/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 22534.4361 - val_loss: 22136.2500\n",
      "Epoch 23/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 21445.3358 - val_loss: 21635.7695\n",
      "Epoch 24/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 21404.9080 - val_loss: 21517.9297\n",
      "Epoch 25/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 19396.3288 - val_loss: 21112.6426\n",
      "Epoch 26/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 20443.5025 - val_loss: 20897.2441\n",
      "Epoch 27/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 19249.2710 - val_loss: 20311.4453\n",
      "Epoch 28/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 20188.1689 - val_loss: 20218.3027\n",
      "Epoch 29/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 19055.2919 - val_loss: 19692.7148\n",
      "Epoch 30/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 20483.9537 - val_loss: 18949.7988\n",
      "Epoch 31/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 18487.2268 - val_loss: 18985.0859\n",
      "Epoch 32/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 18379.1866 - val_loss: 18574.1895\n",
      "Epoch 33/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 18146.7294 - val_loss: 18440.1875\n",
      "Epoch 34/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 17962.8749 - val_loss: 18117.8203\n",
      "Epoch 35/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 17626.3863 - val_loss: 18032.2129\n",
      "Epoch 36/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 18353.9561 - val_loss: 17353.0234\n",
      "Epoch 37/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17425.3672 - val_loss: 17238.3359\n",
      "Epoch 38/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17430.6300 - val_loss: 16941.8750\n",
      "Epoch 39/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 17264.1368 - val_loss: 16574.1309\n",
      "Epoch 40/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15669.3799 - val_loss: 16611.4629\n",
      "Epoch 41/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16266.7249 - val_loss: 16120.2090\n",
      "Epoch 42/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 15566.4821 - val_loss: 16238.3945\n",
      "Epoch 43/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 17434.2748 - val_loss: 16049.3350\n",
      "Epoch 44/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 15250.7921 - val_loss: 15554.0811\n",
      "Epoch 45/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 16085.6872 - val_loss: 15108.8184\n",
      "Epoch 46/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14040.4380 - val_loss: 14913.9971\n",
      "Epoch 47/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 14443.1940 - val_loss: 14735.9258\n",
      "Epoch 48/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13632.5320 - val_loss: 14579.4180\n",
      "Epoch 49/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13842.0850 - val_loss: 14323.7559\n",
      "Epoch 50/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13890.1384 - val_loss: 13819.8662\n",
      "Epoch 51/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13310.0973 - val_loss: 13919.4775\n",
      "Epoch 52/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 13146.3594 - val_loss: 13534.7432\n",
      "Epoch 53/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13820.3952 - val_loss: 13415.0898\n",
      "Epoch 54/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13604.4417 - val_loss: 13192.0371\n",
      "Epoch 55/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 12922.2023 - val_loss: 12471.2217\n",
      "Epoch 56/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 12262.4068 - val_loss: 12541.9492\n",
      "Epoch 57/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 11971.5079 - val_loss: 12728.8779\n",
      "Epoch 58/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 11389.7289 - val_loss: 12540.2754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 12390.7807 - val_loss: 12058.8184\n",
      "Epoch 60/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 11997.2295 - val_loss: 11623.4648\n",
      "Epoch 61/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 11829.3526 - val_loss: 11555.8711\n",
      "Epoch 62/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 11093.5237 - val_loss: 11661.2285\n",
      "Epoch 63/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 11726.0784 - val_loss: 10983.0840\n",
      "Epoch 64/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 11270.8846 - val_loss: 11389.8164\n",
      "Epoch 65/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 10502.5028 - val_loss: 11234.2969\n",
      "Epoch 66/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 10650.8049 - val_loss: 10406.9746\n",
      "Epoch 67/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9871.6329 - val_loss: 10192.1475\n",
      "Epoch 68/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 10813.1919 - val_loss: 10201.2461\n",
      "Epoch 69/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 10369.7761 - val_loss: 10221.8848\n",
      "Epoch 70/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 10527.5209 - val_loss: 10436.8428\n",
      "Epoch 71/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 10478.5470 - val_loss: 9824.7510\n",
      "Epoch 72/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9706.1550 - val_loss: 9501.8213\n",
      "Epoch 73/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 9085.1995 - val_loss: 9531.3271\n",
      "Epoch 74/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 10017.4062 - val_loss: 9169.0547\n",
      "Epoch 75/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9206.5613 - val_loss: 9224.0312\n",
      "Epoch 76/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9040.9803 - val_loss: 9202.8711\n",
      "Epoch 77/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9327.4477 - val_loss: 8467.7725\n",
      "Epoch 78/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8613.6471 - val_loss: 8838.8809\n",
      "Epoch 79/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8764.5395 - val_loss: 8594.4775\n",
      "Epoch 80/1500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 9243.3052 - val_loss: 8656.3135\n",
      "Epoch 81/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8829.9388 - val_loss: 8140.3906\n",
      "Epoch 82/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8986.3347 - val_loss: 7979.3198\n",
      "Epoch 83/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7924.7011 - val_loss: 8410.4521\n",
      "Epoch 84/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8538.5624 - val_loss: 7982.8579\n",
      "Epoch 85/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8382.2083 - val_loss: 7703.0640\n",
      "Epoch 86/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8029.6474 - val_loss: 7760.4937\n",
      "Epoch 87/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7447.5025 - val_loss: 7413.6323\n",
      "Epoch 88/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8367.1741 - val_loss: 7332.8452\n",
      "Epoch 89/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8324.0211 - val_loss: 7289.4927\n",
      "Epoch 90/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7867.6374 - val_loss: 7272.8188\n",
      "Epoch 91/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7985.5577 - val_loss: 7288.5767\n",
      "Epoch 92/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7110.8992 - val_loss: 7116.9248\n",
      "Epoch 93/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7051.2746 - val_loss: 6907.8779\n",
      "Epoch 94/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6722.0416 - val_loss: 6779.0996\n",
      "Epoch 95/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7463.6290 - val_loss: 6618.2651\n",
      "Epoch 96/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6676.6222 - val_loss: 6490.1782\n",
      "Epoch 97/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7165.8506 - val_loss: 6395.6875\n",
      "Epoch 98/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6989.6340 - val_loss: 6391.0220\n",
      "Epoch 99/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6654.1148 - val_loss: 6445.5342\n",
      "Epoch 100/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6854.9657 - val_loss: 6343.3315\n",
      "Epoch 101/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6631.5079 - val_loss: 5803.4038\n",
      "Epoch 102/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6636.9520 - val_loss: 6022.4390\n",
      "Epoch 103/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7129.9404 - val_loss: 5600.3408\n",
      "Epoch 104/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6218.7815 - val_loss: 5932.0996\n",
      "Epoch 105/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6631.0526 - val_loss: 5945.4111\n",
      "Epoch 106/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6170.6693 - val_loss: 5963.0610\n",
      "Epoch 107/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6246.0566 - val_loss: 5930.4868\n",
      "Epoch 108/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6014.0246 - val_loss: 5556.3447\n",
      "Epoch 109/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6315.2035 - val_loss: 5525.5464\n",
      "Epoch 110/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5962.1999 - val_loss: 5071.2144\n",
      "Epoch 111/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 6023.3338 - val_loss: 5488.1724\n",
      "Epoch 112/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5748.4691 - val_loss: 5593.9414\n",
      "Epoch 113/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5704.9801 - val_loss: 5397.2261\n",
      "Epoch 114/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5657.5166 - val_loss: 5105.0732\n",
      "Epoch 115/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5817.2401 - val_loss: 5339.7534\n",
      "Epoch 116/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5633.4604 - val_loss: 4864.3955\n",
      "Epoch 117/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5395.0915 - val_loss: 4755.4233\n",
      "Epoch 118/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5299.3013 - val_loss: 5022.0020\n",
      "Epoch 119/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5254.4235 - val_loss: 5443.2036\n",
      "Epoch 120/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5694.0909 - val_loss: 5005.0972\n",
      "Epoch 121/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5327.3348 - val_loss: 5043.5669\n",
      "Epoch 122/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5531.1169 - val_loss: 4951.0684\n",
      "Epoch 123/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5824.5251 - val_loss: 4969.6035\n",
      "Epoch 124/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5281.9235 - val_loss: 4524.7451\n",
      "Epoch 125/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5158.7343 - val_loss: 4360.6406\n",
      "Epoch 126/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5575.1722 - val_loss: 4613.2368\n",
      "Epoch 127/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4512.2799 - val_loss: 4329.8882\n",
      "Epoch 128/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5118.5456 - val_loss: 4495.4395\n",
      "Epoch 129/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4756.0917 - val_loss: 4323.4619\n",
      "Epoch 130/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4671.3360 - val_loss: 4556.1875\n",
      "Epoch 131/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5126.6621 - val_loss: 4248.6763\n",
      "Epoch 132/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4648.6819 - val_loss: 4070.6790\n",
      "Epoch 133/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 5040.0583 - val_loss: 4473.1016\n",
      "Epoch 134/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4453.0425 - val_loss: 4370.6924\n",
      "Epoch 135/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 5ms/step - loss: 4793.9180 - val_loss: 4416.1182\n",
      "Epoch 136/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5259.4978 - val_loss: 4185.8105\n",
      "Epoch 137/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4666.7834 - val_loss: 3583.8928\n",
      "Epoch 138/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4832.9050 - val_loss: 4109.1904\n",
      "Epoch 139/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4547.7699 - val_loss: 4271.2109\n",
      "Epoch 140/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4695.1450 - val_loss: 3927.4438\n",
      "Epoch 141/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4688.4069 - val_loss: 3924.4326\n",
      "Epoch 142/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4625.9852 - val_loss: 3855.2236\n",
      "Epoch 143/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4863.7441 - val_loss: 3863.1562\n",
      "Epoch 144/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4820.2683 - val_loss: 3441.8257\n",
      "Epoch 145/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4441.0088 - val_loss: 3776.2788\n",
      "Epoch 146/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4364.5513 - val_loss: 3794.1704\n",
      "Epoch 147/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4302.4977 - val_loss: 3711.9204\n",
      "Epoch 148/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4662.5227 - val_loss: 3683.2844\n",
      "Epoch 149/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4534.5441 - val_loss: 3872.9688\n",
      "Epoch 150/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4303.8640 - val_loss: 3785.4534\n",
      "Epoch 151/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4273.9131 - val_loss: 3885.8132\n",
      "Epoch 152/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4421.7575 - val_loss: 3625.2563\n",
      "Epoch 153/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4346.9397 - val_loss: 3448.4814\n",
      "Epoch 154/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4223.9327 - val_loss: 4017.8149\n",
      "Epoch 155/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4323.0257 - val_loss: 3710.5107\n",
      "Epoch 156/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4453.7286 - val_loss: 3570.2407\n",
      "Epoch 157/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4460.1199 - val_loss: 3185.6448\n",
      "Epoch 158/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4001.5060 - val_loss: 3276.6221\n",
      "Epoch 159/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3881.6462 - val_loss: 3348.8533\n",
      "Epoch 160/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3998.5147 - val_loss: 3573.8787\n",
      "Epoch 161/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4580.2691 - val_loss: 3762.2915\n",
      "Epoch 162/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4399.1149 - val_loss: 3581.6001\n",
      "Epoch 163/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4085.8763 - val_loss: 3368.2336\n",
      "Epoch 164/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4379.0135 - val_loss: 3308.1101\n",
      "Epoch 165/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3998.8710 - val_loss: 3374.6243\n",
      "Epoch 166/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4072.1136 - val_loss: 3226.0193\n",
      "Epoch 167/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4185.2504 - val_loss: 3546.1877\n",
      "Epoch 168/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4636.0244 - val_loss: 3480.0234\n",
      "Epoch 169/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4318.0245 - val_loss: 3249.5945\n",
      "Epoch 170/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4204.7814 - val_loss: 3441.1768\n",
      "Epoch 171/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4774.0299 - val_loss: 3309.6296\n",
      "Epoch 172/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4067.2598 - val_loss: 3402.9639\n",
      "Epoch 173/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4091.4994 - val_loss: 3355.4717\n",
      "Epoch 174/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4031.3985 - val_loss: 3086.6018\n",
      "Epoch 175/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4283.1100 - val_loss: 3704.7776\n",
      "Epoch 176/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4121.9644 - val_loss: 3026.2419\n",
      "Epoch 177/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3813.3470 - val_loss: 3176.9592\n",
      "Epoch 178/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3893.1574 - val_loss: 3410.6313\n",
      "Epoch 179/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4025.6975 - val_loss: 3433.5320\n",
      "Epoch 180/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4319.3415 - val_loss: 3170.1899\n",
      "Epoch 181/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4464.6515 - val_loss: 3350.8416\n",
      "Epoch 182/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4078.0359 - val_loss: 3220.9294\n",
      "Epoch 183/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4429.2791 - val_loss: 3215.7571\n",
      "Epoch 184/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4518.3967 - val_loss: 3479.2642\n",
      "Epoch 185/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3975.5323 - val_loss: 3464.0110\n",
      "Epoch 186/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4059.7755 - val_loss: 3120.1416\n",
      "Epoch 187/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4129.4743 - val_loss: 3398.6414\n",
      "Epoch 188/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4530.7000 - val_loss: 3344.7510\n",
      "Epoch 189/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4137.2804 - val_loss: 3663.9241\n",
      "Epoch 190/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4065.7010 - val_loss: 3358.6179\n",
      "Epoch 191/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3761.2709 - val_loss: 3082.0120\n",
      "Epoch 192/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4125.5878 - val_loss: 2810.8274\n",
      "Epoch 193/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4064.7961 - val_loss: 3444.3792\n",
      "Epoch 194/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3909.0689 - val_loss: 3462.7344\n",
      "Epoch 195/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3918.2964 - val_loss: 3198.7532\n",
      "Epoch 196/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3894.3899 - val_loss: 2894.2405\n",
      "Epoch 197/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3887.2777 - val_loss: 3580.8232\n",
      "Epoch 198/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3781.0694 - val_loss: 3107.2803\n",
      "Epoch 199/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4286.1650 - val_loss: 3209.0334\n",
      "Epoch 200/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4161.2828 - val_loss: 3370.0920\n",
      "Epoch 201/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4196.8706 - val_loss: 3402.4958\n",
      "Epoch 202/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3857.5139 - val_loss: 3129.9468\n",
      "Epoch 203/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3954.8590 - val_loss: 3113.4688\n",
      "Epoch 204/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3878.7717 - val_loss: 3084.0952\n",
      "Epoch 205/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4214.5317 - val_loss: 3316.8643\n",
      "Epoch 206/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4135.6837 - val_loss: 3273.5618\n",
      "Epoch 207/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3943.8417 - val_loss: 3563.6475\n",
      "Epoch 208/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3569.2222 - val_loss: 3285.9502\n",
      "Epoch 209/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4044.2119 - val_loss: 3248.6140\n",
      "Epoch 210/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4054.4233 - val_loss: 2926.6345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4306.0528 - val_loss: 2900.7930\n",
      "Epoch 212/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4371.0415 - val_loss: 3126.2510\n",
      "Epoch 213/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4131.5078 - val_loss: 3318.8604\n",
      "Epoch 214/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4130.9527 - val_loss: 3184.6094\n",
      "Epoch 215/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4267.0220 - val_loss: 3306.4658\n",
      "Epoch 216/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3876.0264 - val_loss: 3479.3877\n",
      "Epoch 217/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4422.5309 - val_loss: 3130.2671\n",
      "Epoch 218/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4115.8521 - val_loss: 3340.3877\n",
      "Epoch 219/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3859.0030 - val_loss: 3053.4841\n",
      "Epoch 220/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4481.2561 - val_loss: 3123.8093\n",
      "Epoch 221/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4612.6045 - val_loss: 3126.9495\n",
      "Epoch 222/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4117.8677 - val_loss: 3282.9048\n",
      "Epoch 223/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4486.0460 - val_loss: 3357.6768\n",
      "Epoch 224/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4082.4623 - val_loss: 3132.8032\n",
      "Epoch 225/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4256.9709 - val_loss: 3281.1594\n",
      "Epoch 226/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4264.6094 - val_loss: 2907.9431\n",
      "Epoch 227/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4093.6933 - val_loss: 3275.4729\n",
      "Epoch 228/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4251.7502 - val_loss: 3419.9197\n",
      "Epoch 229/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4175.4615 - val_loss: 3255.8843\n",
      "Epoch 230/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4635.2769 - val_loss: 3217.2898\n",
      "Epoch 231/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4039.6053 - val_loss: 2946.6194\n",
      "Epoch 232/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3982.8071 - val_loss: 2958.1445\n",
      "Epoch 233/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4170.1923 - val_loss: 3046.3135\n",
      "Epoch 234/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4152.7080 - val_loss: 3217.7131\n",
      "Epoch 235/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3888.2872 - val_loss: 3144.5647\n",
      "Epoch 236/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4254.9926 - val_loss: 3258.9773\n",
      "Epoch 237/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4138.0994 - val_loss: 3549.7251\n",
      "Epoch 238/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4133.0512 - val_loss: 2955.5085\n",
      "Epoch 239/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4364.9175 - val_loss: 3480.4397\n",
      "Epoch 240/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4130.9289 - val_loss: 3147.7429\n",
      "Epoch 241/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4019.6182 - val_loss: 2948.1541\n",
      "Epoch 242/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4500.9380 - val_loss: 3006.6299\n",
      "Epoch 243/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4328.0778 - val_loss: 3064.5063\n",
      "Epoch 244/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4433.3546 - val_loss: 3055.2405\n",
      "Epoch 245/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4106.0195 - val_loss: 3135.6492\n",
      "Epoch 246/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4321.0368 - val_loss: 3052.8772\n",
      "Epoch 247/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3872.7104 - val_loss: 3487.5295\n",
      "Epoch 248/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4053.6327 - val_loss: 2519.6787\n",
      "Epoch 249/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4169.7706 - val_loss: 3240.0891\n",
      "Epoch 250/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3866.9847 - val_loss: 3181.3037\n",
      "Epoch 251/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4184.5281 - val_loss: 3063.4531\n",
      "Epoch 252/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3905.8954 - val_loss: 3069.5869\n",
      "Epoch 253/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3826.6674 - val_loss: 2883.4915\n",
      "Epoch 254/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3999.6871 - val_loss: 3097.9553\n",
      "Epoch 255/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3848.7696 - val_loss: 3061.0076\n",
      "Epoch 256/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4605.4262 - val_loss: 2979.7202\n",
      "Epoch 257/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4346.0341 - val_loss: 3430.1729\n",
      "Epoch 258/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3970.9802 - val_loss: 3093.2080\n",
      "Epoch 259/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4148.4248 - val_loss: 3015.1689\n",
      "Epoch 260/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4234.3889 - val_loss: 3177.4915\n",
      "Epoch 261/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4563.5512 - val_loss: 3183.9812\n",
      "Epoch 262/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3929.2181 - val_loss: 3311.0842\n",
      "Epoch 263/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4226.8908 - val_loss: 3629.5366\n",
      "Epoch 264/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3832.4131 - val_loss: 3459.0994\n",
      "Epoch 265/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4278.3550 - val_loss: 3212.0054\n",
      "Epoch 266/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4376.5380 - val_loss: 3611.1001\n",
      "Epoch 267/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3975.9538 - val_loss: 3168.4031\n",
      "Epoch 268/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4471.9885 - val_loss: 3214.8303\n",
      "Epoch 269/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4014.3536 - val_loss: 3362.5039\n",
      "Epoch 270/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4030.0724 - val_loss: 3155.3728\n",
      "Epoch 271/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4380.0671 - val_loss: 3052.5562\n",
      "Epoch 272/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4043.6208 - val_loss: 3164.5220\n",
      "Epoch 273/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3973.2642 - val_loss: 3412.8804\n",
      "Epoch 274/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4001.8869 - val_loss: 3198.6533\n",
      "Epoch 275/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4001.8821 - val_loss: 3291.6201\n",
      "Epoch 276/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4000.4182 - val_loss: 3197.3501\n",
      "Epoch 277/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4343.9900 - val_loss: 3282.5110\n",
      "Epoch 278/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3886.7941 - val_loss: 2822.7515\n",
      "Epoch 279/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4251.6449 - val_loss: 3217.1257\n",
      "Epoch 280/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4376.5869 - val_loss: 3703.2952\n",
      "Epoch 281/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3762.0573 - val_loss: 2632.7947\n",
      "Epoch 282/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4501.9999 - val_loss: 3226.0767\n",
      "Epoch 283/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4351.4152 - val_loss: 2933.4600\n",
      "Epoch 284/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4052.0766 - val_loss: 2732.4231\n",
      "Epoch 285/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4132.8473 - val_loss: 2931.1399\n",
      "Epoch 286/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4383.3182 - val_loss: 3166.4897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4406.1653 - val_loss: 3442.4724\n",
      "Epoch 288/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3890.4598 - val_loss: 3561.2983\n",
      "Epoch 289/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4186.5206 - val_loss: 3032.6914\n",
      "Epoch 290/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4278.4782 - val_loss: 3049.9946\n",
      "Epoch 291/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4716.8881 - val_loss: 3112.0359\n",
      "Epoch 292/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4040.3263 - val_loss: 3027.4880\n",
      "Epoch 293/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4236.4815 - val_loss: 3164.6860\n",
      "Epoch 294/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4067.1938 - val_loss: 3260.2732\n",
      "Epoch 295/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4153.3374 - val_loss: 2982.2976\n",
      "Epoch 296/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4195.3547 - val_loss: 3079.1079\n",
      "Epoch 297/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4037.4772 - val_loss: 2962.0796\n",
      "Epoch 298/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4455.7429 - val_loss: 3001.7202\n",
      "Epoch 299/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4200.8637 - val_loss: 3381.9177\n",
      "Epoch 300/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4205.2427 - val_loss: 3028.9109\n",
      "Epoch 301/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4514.5580 - val_loss: 3096.6929\n",
      "Epoch 302/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4281.5825 - val_loss: 3055.9958\n",
      "Epoch 303/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4056.8655 - val_loss: 3402.7771\n",
      "Epoch 304/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4114.6930 - val_loss: 3122.9963\n",
      "Epoch 305/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4409.3875 - val_loss: 3234.9932\n",
      "Epoch 306/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3913.6704 - val_loss: 3044.9517\n",
      "Epoch 307/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4344.6483 - val_loss: 3142.4873\n",
      "Epoch 308/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4194.9638 - val_loss: 3101.0171\n",
      "Epoch 309/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3727.1883 - val_loss: 3129.6445\n",
      "Epoch 310/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4348.7102 - val_loss: 3527.6331\n",
      "Epoch 311/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4025.9231 - val_loss: 2891.1521\n",
      "Epoch 312/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4440.7354 - val_loss: 3168.8040\n",
      "Epoch 313/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4205.8892 - val_loss: 2937.9866\n",
      "Epoch 314/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4058.6405 - val_loss: 3158.6499\n",
      "Epoch 315/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4562.1307 - val_loss: 3081.1335\n",
      "Epoch 316/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4058.7419 - val_loss: 3016.5085\n",
      "Epoch 317/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4065.2681 - val_loss: 3036.8789\n",
      "Epoch 318/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4151.0906 - val_loss: 3444.0901\n",
      "Epoch 319/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4238.6863 - val_loss: 3660.5693\n",
      "Epoch 320/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4097.1699 - val_loss: 3100.2458\n",
      "Epoch 321/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3922.0814 - val_loss: 3087.2529\n",
      "Epoch 322/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4179.5493 - val_loss: 3171.7205\n",
      "Epoch 323/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4204.6402 - val_loss: 2989.0312\n",
      "Epoch 324/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3936.9131 - val_loss: 3255.2351\n",
      "Epoch 325/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3914.8676 - val_loss: 2550.2275\n",
      "Epoch 326/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4764.0322 - val_loss: 3325.9119\n",
      "Epoch 327/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4149.2156 - val_loss: 3166.2639\n",
      "Epoch 328/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4311.0955 - val_loss: 3027.6016\n",
      "Epoch 329/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3989.7599 - val_loss: 3261.4607\n",
      "Epoch 330/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4240.0505 - val_loss: 2963.9827\n",
      "Epoch 331/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3665.2106 - val_loss: 3097.9275\n",
      "Epoch 332/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4279.8446 - val_loss: 3403.1577\n",
      "Epoch 333/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4024.7196 - val_loss: 3073.1265\n",
      "Epoch 334/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4329.0945 - val_loss: 2987.0625\n",
      "Epoch 335/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4446.9058 - val_loss: 3049.6248\n",
      "Epoch 336/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4120.4780 - val_loss: 3122.3062\n",
      "Epoch 337/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4146.2039 - val_loss: 3256.7961\n",
      "Epoch 338/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4074.9289 - val_loss: 3018.8047\n",
      "Epoch 339/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4365.2012 - val_loss: 3210.1001\n",
      "Epoch 340/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3982.0468 - val_loss: 3017.2478\n",
      "Epoch 341/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4065.6789 - val_loss: 3359.6279\n",
      "Epoch 342/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4058.4059 - val_loss: 3122.6694\n",
      "Epoch 343/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4081.8245 - val_loss: 3631.5259\n",
      "Epoch 344/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4364.3836 - val_loss: 3408.7053\n",
      "Epoch 345/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4008.9960 - val_loss: 2863.9641\n",
      "Epoch 346/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4098.9524 - val_loss: 3065.0999\n",
      "Epoch 347/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4294.5428 - val_loss: 3052.4729\n",
      "Epoch 348/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4346.5813 - val_loss: 3271.7346\n",
      "Epoch 349/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4033.6565 - val_loss: 2991.2517\n",
      "Epoch 350/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3974.3624 - val_loss: 3140.3643\n",
      "Epoch 351/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4598.0673 - val_loss: 2961.9617\n",
      "Epoch 352/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4456.4238 - val_loss: 3521.9880\n",
      "Epoch 353/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4013.8296 - val_loss: 3327.6279\n",
      "Epoch 354/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4033.5268 - val_loss: 3322.1711\n",
      "Epoch 355/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4305.3644 - val_loss: 2981.7234\n",
      "Epoch 356/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4044.5063 - val_loss: 3150.6538\n",
      "Epoch 357/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4217.1727 - val_loss: 3023.1782\n",
      "Epoch 358/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4210.8632 - val_loss: 3120.9944\n",
      "Epoch 359/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4471.8646 - val_loss: 3260.6658\n",
      "Epoch 360/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3995.9077 - val_loss: 2962.5613\n",
      "Epoch 361/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4169.9177 - val_loss: 3182.1562\n",
      "Epoch 362/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4335.3193 - val_loss: 3059.3743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4123.0039 - val_loss: 3358.3350\n",
      "Epoch 364/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3997.5063 - val_loss: 3050.3445\n",
      "Epoch 365/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4204.5090 - val_loss: 2908.0986\n",
      "Epoch 366/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4234.9705 - val_loss: 3010.6858\n",
      "Epoch 367/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4337.8742 - val_loss: 2962.5193\n",
      "Epoch 368/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4062.2322 - val_loss: 3136.4568\n",
      "Epoch 369/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4172.1023 - val_loss: 2801.3655\n",
      "Epoch 370/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4294.2914 - val_loss: 2999.1787\n",
      "Epoch 371/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4371.4292 - val_loss: 3106.4468\n",
      "Epoch 372/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4483.5651 - val_loss: 2647.1821\n",
      "Epoch 373/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4012.2291 - val_loss: 3135.7419\n",
      "Epoch 374/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4193.6836 - val_loss: 3354.9695\n",
      "Epoch 375/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3959.9838 - val_loss: 3683.1604\n",
      "Epoch 376/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3958.7088 - val_loss: 3165.7607\n",
      "Epoch 377/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3860.2576 - val_loss: 3453.6299\n",
      "Epoch 378/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3800.2047 - val_loss: 2986.3232\n",
      "Epoch 379/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4414.1981 - val_loss: 3465.3032\n",
      "Epoch 380/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4234.9277 - val_loss: 3044.3735\n",
      "Epoch 381/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3969.6897 - val_loss: 3169.7017\n",
      "Epoch 382/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4195.5062 - val_loss: 2869.1316\n",
      "Epoch 383/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4094.3046 - val_loss: 3130.3281\n",
      "Epoch 384/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4603.3118 - val_loss: 3195.4688\n",
      "Epoch 385/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4007.1764 - val_loss: 2715.0554\n",
      "Epoch 386/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4372.1672 - val_loss: 3110.3689\n",
      "Epoch 387/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4020.2104 - val_loss: 2957.9001\n",
      "Epoch 388/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4192.1266 - val_loss: 3248.4783\n",
      "Epoch 389/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4059.5803 - val_loss: 3352.3389\n",
      "Epoch 390/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4381.7471 - val_loss: 3156.0764\n",
      "Epoch 391/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4295.2293 - val_loss: 2958.4651\n",
      "Epoch 392/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4342.8320 - val_loss: 3300.2039\n",
      "Epoch 393/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3646.7663 - val_loss: 3366.5693\n",
      "Epoch 394/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4094.3380 - val_loss: 3201.4868\n",
      "Epoch 395/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4473.8087 - val_loss: 3365.3792\n",
      "Epoch 396/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3943.1307 - val_loss: 3312.2820\n",
      "Epoch 397/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4188.1203 - val_loss: 3216.9072\n",
      "Epoch 398/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3903.7167 - val_loss: 3557.2932\n",
      "Epoch 399/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4111.8940 - val_loss: 3343.9546\n",
      "Epoch 400/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4280.8184 - val_loss: 3533.7073\n",
      "Epoch 401/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4444.0190 - val_loss: 3380.7046\n",
      "Epoch 402/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4373.8210 - val_loss: 3154.4609\n",
      "Epoch 403/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4130.2343 - val_loss: 3063.5354\n",
      "Epoch 404/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4014.9126 - val_loss: 3106.6760\n",
      "Epoch 405/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4163.9313 - val_loss: 2858.3474\n",
      "Epoch 406/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4158.9810 - val_loss: 3441.6416\n",
      "Epoch 407/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3685.9729 - val_loss: 3416.6799\n",
      "Epoch 408/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 4354.9557 - val_loss: 3572.3018\n",
      "Epoch 409/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3880.7205 - val_loss: 3582.1116\n",
      "Epoch 410/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4084.0433 - val_loss: 3062.7095\n",
      "Epoch 411/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3979.0379 - val_loss: 2739.5110\n",
      "Epoch 412/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3995.8074 - val_loss: 3260.5693\n",
      "Epoch 413/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3938.5865 - val_loss: 3498.9272\n",
      "Epoch 414/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4262.6403 - val_loss: 3155.7842\n",
      "Epoch 415/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4393.2062 - val_loss: 2979.3943\n",
      "Epoch 416/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4300.2302 - val_loss: 3331.4922\n",
      "Epoch 417/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4013.3330 - val_loss: 2758.0818\n",
      "Epoch 418/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4208.3203 - val_loss: 3081.9709\n",
      "Epoch 419/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3829.7230 - val_loss: 3354.3127\n",
      "Epoch 420/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4014.8548 - val_loss: 3033.5298\n",
      "Epoch 421/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4210.6248 - val_loss: 3228.3252\n",
      "Epoch 422/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4015.6190 - val_loss: 3063.3687\n",
      "Epoch 423/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4221.2522 - val_loss: 3025.4937\n",
      "Epoch 424/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4232.3303 - val_loss: 3486.3774\n",
      "Epoch 425/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4247.3438 - val_loss: 2916.5298\n",
      "Epoch 426/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3870.6850 - val_loss: 2853.6702\n",
      "Epoch 427/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4134.1223 - val_loss: 2898.2107\n",
      "Epoch 428/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3812.5393 - val_loss: 3114.2458\n",
      "Epoch 429/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4243.9791 - val_loss: 2963.0896\n",
      "Epoch 430/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4258.3322 - val_loss: 3294.9248\n",
      "Epoch 431/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4450.1577 - val_loss: 3037.0579\n",
      "Epoch 432/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4206.5172 - val_loss: 2955.1558\n",
      "Epoch 433/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4141.8088 - val_loss: 3491.2898\n",
      "Epoch 434/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4015.8964 - val_loss: 3253.2976\n",
      "Epoch 435/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4211.2734 - val_loss: 3026.4131\n",
      "Epoch 436/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3960.1944 - val_loss: 3009.3193\n",
      "Epoch 437/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4263.0231 - val_loss: 3380.7322\n",
      "Epoch 438/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4156.7081 - val_loss: 3234.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3985.4634 - val_loss: 2584.7993\n",
      "Epoch 440/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4158.2867 - val_loss: 3065.6875\n",
      "Epoch 441/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4117.6638 - val_loss: 3214.8174\n",
      "Epoch 442/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4297.0344 - val_loss: 3277.3298\n",
      "Epoch 443/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4133.5712 - val_loss: 3517.5315\n",
      "Epoch 444/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4070.1260 - val_loss: 3072.0718\n",
      "Epoch 445/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3886.5254 - val_loss: 3323.2080\n",
      "Epoch 446/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4393.9448 - val_loss: 3238.3752\n",
      "Epoch 447/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4143.9342 - val_loss: 3076.9958\n",
      "Epoch 448/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4357.2633 - val_loss: 3203.0381\n",
      "Epoch 449/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4060.6157 - val_loss: 3048.8352\n",
      "Epoch 450/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4276.4717 - val_loss: 3195.7522\n",
      "Epoch 451/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3865.5519 - val_loss: 2800.7195\n",
      "Epoch 452/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3877.4374 - val_loss: 3096.2119\n",
      "Epoch 453/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4107.9424 - val_loss: 3250.0015\n",
      "Epoch 454/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4271.1927 - val_loss: 3355.4858\n",
      "Epoch 455/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4065.8126 - val_loss: 3488.5039\n",
      "Epoch 456/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4024.5421 - val_loss: 3011.2883\n",
      "Epoch 457/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4164.5463 - val_loss: 3154.3826\n",
      "Epoch 458/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4051.6379 - val_loss: 2750.2922\n",
      "Epoch 459/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4218.4345 - val_loss: 3262.1487\n",
      "Epoch 460/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4304.2017 - val_loss: 3493.9446\n",
      "Epoch 461/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4258.5488 - val_loss: 3029.0681\n",
      "Epoch 462/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4225.5806 - val_loss: 3562.2693\n",
      "Epoch 463/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4276.6047 - val_loss: 3145.9233\n",
      "Epoch 464/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3869.1286 - val_loss: 3290.7070\n",
      "Epoch 465/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4239.1173 - val_loss: 3326.1624\n",
      "Epoch 466/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3981.9127 - val_loss: 3498.5369\n",
      "Epoch 467/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3880.8416 - val_loss: 3466.6970\n",
      "Epoch 468/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4282.1073 - val_loss: 3147.5803\n",
      "Epoch 469/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4473.9590 - val_loss: 3137.7344\n",
      "Epoch 470/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3907.0896 - val_loss: 3029.3149\n",
      "Epoch 471/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4407.9734 - val_loss: 3171.3577\n",
      "Epoch 472/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4169.8104 - val_loss: 3156.6604\n",
      "Epoch 473/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3845.9348 - val_loss: 3102.5859\n",
      "Epoch 474/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3948.7829 - val_loss: 3019.4573\n",
      "Epoch 475/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4074.8333 - val_loss: 3340.9922\n",
      "Epoch 476/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4225.3226 - val_loss: 2964.0586\n",
      "Epoch 477/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3834.8131 - val_loss: 3148.4783\n",
      "Epoch 478/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4183.7818 - val_loss: 3380.1697\n",
      "Epoch 479/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3925.6211 - val_loss: 3489.3088\n",
      "Epoch 480/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4619.9731 - val_loss: 3259.0725\n",
      "Epoch 481/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3868.7301 - val_loss: 3253.2712\n",
      "Epoch 482/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4401.3750 - val_loss: 2988.5022\n",
      "Epoch 483/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4319.5845 - val_loss: 3175.2227\n",
      "Epoch 484/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4487.2858 - val_loss: 3072.6384\n",
      "Epoch 485/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3941.4113 - val_loss: 3524.8508\n",
      "Epoch 486/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4487.8828 - val_loss: 2942.7327\n",
      "Epoch 487/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3897.3378 - val_loss: 3229.7429\n",
      "Epoch 488/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4517.8423 - val_loss: 3051.2837\n",
      "Epoch 489/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3917.0187 - val_loss: 3179.5498\n",
      "Epoch 490/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4051.3598 - val_loss: 3065.3552\n",
      "Epoch 491/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4346.9972 - val_loss: 2921.5977\n",
      "Epoch 492/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4004.7149 - val_loss: 3002.2681\n",
      "Epoch 493/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4118.8538 - val_loss: 3216.3430\n",
      "Epoch 494/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3965.7564 - val_loss: 2772.1609\n",
      "Epoch 495/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4625.0508 - val_loss: 3221.2258\n",
      "Epoch 496/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4042.7550 - val_loss: 2952.8689\n",
      "Epoch 497/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4326.2371 - val_loss: 3368.1077\n",
      "Epoch 498/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3918.1754 - val_loss: 3197.5696\n",
      "Epoch 499/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4178.0626 - val_loss: 2914.5508\n",
      "Epoch 500/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4323.4175 - val_loss: 3305.9431\n",
      "Epoch 501/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4263.4320 - val_loss: 3373.2163\n",
      "Epoch 502/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4064.1126 - val_loss: 3361.9985\n",
      "Epoch 503/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4094.1343 - val_loss: 3137.3062\n",
      "Epoch 504/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4154.6494 - val_loss: 3074.7446\n",
      "Epoch 505/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4530.7157 - val_loss: 3076.0000\n",
      "Epoch 506/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4052.6380 - val_loss: 3169.3240\n",
      "Epoch 507/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4082.1737 - val_loss: 3272.4460\n",
      "Epoch 508/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3921.5999 - val_loss: 2943.5967\n",
      "Epoch 509/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3932.5658 - val_loss: 3317.4958\n",
      "Epoch 510/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4138.1650 - val_loss: 3108.3240\n",
      "Epoch 511/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4319.1686 - val_loss: 3359.0413\n",
      "Epoch 512/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4150.7590 - val_loss: 3160.4133\n",
      "Epoch 513/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4517.9654 - val_loss: 3017.6062\n",
      "Epoch 514/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4488.4618 - val_loss: 3079.1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4438.1829 - val_loss: 3193.2529\n",
      "Epoch 516/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3936.7658 - val_loss: 3189.1321\n",
      "Epoch 517/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4005.8152 - val_loss: 3488.0889\n",
      "Epoch 518/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4362.9161 - val_loss: 3272.8740\n",
      "Epoch 519/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4416.3082 - val_loss: 2864.7217\n",
      "Epoch 520/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3874.8186 - val_loss: 3331.0991\n",
      "Epoch 521/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4084.6981 - val_loss: 3485.5327\n",
      "Epoch 522/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4157.0016 - val_loss: 3122.8655\n",
      "Epoch 523/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4003.5624 - val_loss: 3142.4634\n",
      "Epoch 524/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4151.4892 - val_loss: 3648.4385\n",
      "Epoch 525/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3907.5738 - val_loss: 2881.7463\n",
      "Epoch 526/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3892.6861 - val_loss: 3093.1697\n",
      "Epoch 527/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3978.9957 - val_loss: 3007.1038\n",
      "Epoch 528/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4419.5520 - val_loss: 3083.0166\n",
      "Epoch 529/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3897.0555 - val_loss: 3402.2224\n",
      "Epoch 530/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4042.3440 - val_loss: 3296.7195\n",
      "Epoch 531/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4275.2228 - val_loss: 3225.4006\n",
      "Epoch 532/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4321.7401 - val_loss: 2956.2737\n",
      "Epoch 533/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4206.7195 - val_loss: 3044.8682\n",
      "Epoch 534/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3985.2925 - val_loss: 3200.0068\n",
      "Epoch 535/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4766.5164 - val_loss: 3231.9177\n",
      "Epoch 536/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4099.3772 - val_loss: 3014.2451\n",
      "Epoch 537/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4153.2546 - val_loss: 3083.1956\n",
      "Epoch 538/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3473.3833 - val_loss: 3481.6384\n",
      "Epoch 539/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 3821.5394 - val_loss: 3553.5674\n",
      "Epoch 540/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 3374.8529 - val_loss: 3487.7854\n",
      "Epoch 541/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2693.5992 - val_loss: 5331.0347\n",
      "Epoch 542/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2806.4733 - val_loss: 4281.5928\n",
      "Epoch 543/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2483.5654 - val_loss: 5064.8872\n",
      "Epoch 544/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2506.1872 - val_loss: 4446.3638\n",
      "Epoch 545/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2682.9387 - val_loss: 5243.6030\n",
      "Epoch 546/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2514.4889 - val_loss: 5244.6250\n",
      "Epoch 547/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2137.8892 - val_loss: 4811.8999\n",
      "Epoch 548/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2156.4578 - val_loss: 4083.7046\n",
      "Epoch 549/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2095.9922 - val_loss: 4010.5859\n",
      "Epoch 550/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2281.1378 - val_loss: 4874.5332\n",
      "Epoch 551/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2189.7587 - val_loss: 4359.3071\n",
      "Epoch 552/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1781.0980 - val_loss: 3216.2229\n",
      "Epoch 553/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2323.7266 - val_loss: 3464.8564\n",
      "Epoch 554/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1876.2395 - val_loss: 4379.8550\n",
      "Epoch 555/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 2052.2146 - val_loss: 5675.2847\n",
      "Epoch 556/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1740.9466 - val_loss: 4624.0269\n",
      "Epoch 557/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1813.2161 - val_loss: 3925.7810\n",
      "Epoch 558/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1859.2739 - val_loss: 4795.9917\n",
      "Epoch 559/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1498.1504 - val_loss: 4709.3877\n",
      "Epoch 560/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1658.2866 - val_loss: 3504.3562\n",
      "Epoch 561/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1608.2751 - val_loss: 5856.1030\n",
      "Epoch 562/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1628.3705 - val_loss: 4193.0083\n",
      "Epoch 563/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1736.9182 - val_loss: 4255.5063\n",
      "Epoch 564/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1326.3497 - val_loss: 3861.7507\n",
      "Epoch 565/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1279.0313 - val_loss: 4120.4502\n",
      "Epoch 566/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1681.5613 - val_loss: 4030.6069\n",
      "Epoch 567/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1660.9464 - val_loss: 4035.0205\n",
      "Epoch 568/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1506.1408 - val_loss: 4331.3457\n",
      "Epoch 569/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1398.7225 - val_loss: 4587.8906\n",
      "Epoch 570/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1364.8837 - val_loss: 4366.4121\n",
      "Epoch 571/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1348.8094 - val_loss: 5356.3755\n",
      "Epoch 572/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1354.4471 - val_loss: 3961.0220\n",
      "Epoch 573/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1508.5509 - val_loss: 4638.0020\n",
      "Epoch 574/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1344.8818 - val_loss: 4130.4829\n",
      "Epoch 575/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1233.9569 - val_loss: 3110.0522\n",
      "Epoch 576/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1146.1157 - val_loss: 4161.0874\n",
      "Epoch 577/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1396.9158 - val_loss: 5053.5430\n",
      "Epoch 578/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1154.9128 - val_loss: 4619.4819\n",
      "Epoch 579/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1344.7768 - val_loss: 4428.5112\n",
      "Epoch 580/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1317.2195 - val_loss: 3953.1257\n",
      "Epoch 581/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1127.6529 - val_loss: 6237.8594\n",
      "Epoch 582/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1045.6224 - val_loss: 5163.9233\n",
      "Epoch 583/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1184.2986 - val_loss: 4706.3813\n",
      "Epoch 584/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1068.2411 - val_loss: 4435.6738\n",
      "Epoch 585/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1013.9445 - val_loss: 5056.3667\n",
      "Epoch 586/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1100.6650 - val_loss: 4522.4883\n",
      "Epoch 587/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1113.5973 - val_loss: 4004.5789\n",
      "Epoch 588/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1011.2084 - val_loss: 5084.5483\n",
      "Epoch 589/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 887.4334 - val_loss: 5368.8208\n",
      "Epoch 590/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 956.1136 - val_loss: 5193.6426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1057.0239 - val_loss: 3999.9705\n",
      "Epoch 592/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 867.3438 - val_loss: 4689.9253\n",
      "Epoch 593/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1024.4559 - val_loss: 5206.2207\n",
      "Epoch 594/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 921.8947 - val_loss: 5426.0073\n",
      "Epoch 595/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 912.2747 - val_loss: 4313.1392\n",
      "Epoch 596/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 943.8252 - val_loss: 5189.9199\n",
      "Epoch 597/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 895.8036 - val_loss: 5183.7109\n",
      "Epoch 598/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1044.9439 - val_loss: 3729.6953\n",
      "Epoch 599/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1109.9377 - val_loss: 5705.3296\n",
      "Epoch 600/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 985.7179 - val_loss: 5920.5034\n",
      "Epoch 601/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 931.3785 - val_loss: 3906.8181\n",
      "Epoch 602/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 725.3860 - val_loss: 4345.0308\n",
      "Epoch 603/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 800.7481 - val_loss: 5127.2437\n",
      "Epoch 604/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 837.2201 - val_loss: 5052.1265\n",
      "Epoch 605/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 683.4908 - val_loss: 6243.6284\n",
      "Epoch 606/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 1041.1057 - val_loss: 4890.6377\n",
      "Epoch 607/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 978.1493 - val_loss: 6225.0049\n",
      "Epoch 608/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 835.2250 - val_loss: 5005.5098\n",
      "Epoch 609/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 864.1603 - val_loss: 4536.1675\n",
      "Epoch 610/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 711.9244 - val_loss: 4884.4927\n",
      "Epoch 611/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 675.3060 - val_loss: 4677.4409\n",
      "Epoch 612/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 889.0154 - val_loss: 5831.4502\n",
      "Epoch 613/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 819.2966 - val_loss: 5666.0308\n",
      "Epoch 614/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 694.3786 - val_loss: 6562.2061\n",
      "Epoch 615/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 745.9477 - val_loss: 4653.3315\n",
      "Epoch 616/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 723.6064 - val_loss: 4675.8218\n",
      "Epoch 617/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 723.3031 - val_loss: 5050.3608\n",
      "Epoch 618/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 723.2527 - val_loss: 6457.7373\n",
      "Epoch 619/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 715.9055 - val_loss: 5192.1904\n",
      "Epoch 620/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 720.2176 - val_loss: 3638.5625\n",
      "Epoch 621/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 809.0817 - val_loss: 4035.3438\n",
      "Epoch 622/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 670.0136 - val_loss: 5499.1689\n",
      "Epoch 623/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 593.9833 - val_loss: 7207.0078\n",
      "Epoch 624/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 710.2955 - val_loss: 4525.7080\n",
      "Epoch 625/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 725.1025 - val_loss: 5046.6348\n",
      "Epoch 626/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 798.6303 - val_loss: 5853.4976\n",
      "Epoch 627/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 756.5055 - val_loss: 6933.2402\n",
      "Epoch 628/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 659.4054 - val_loss: 4093.8220\n",
      "Epoch 629/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 650.5645 - val_loss: 5717.3560\n",
      "Epoch 630/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 660.9430 - val_loss: 3352.0244\n",
      "Epoch 631/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 769.5036 - val_loss: 5152.6245\n",
      "Epoch 632/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 588.4139 - val_loss: 4874.0078\n",
      "Epoch 633/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 658.8811 - val_loss: 5310.0259\n",
      "Epoch 634/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 626.8910 - val_loss: 5419.1890\n",
      "Epoch 635/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 677.9547 - val_loss: 5273.4106\n",
      "Epoch 636/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 546.0763 - val_loss: 5294.4067\n",
      "Epoch 637/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 608.1372 - val_loss: 4492.9517\n",
      "Epoch 638/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 612.2909 - val_loss: 5382.5811\n",
      "Epoch 639/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 590.7696 - val_loss: 5475.1191\n",
      "Epoch 640/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 538.3421 - val_loss: 3331.6697\n",
      "Epoch 641/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 691.1016 - val_loss: 4311.1050\n",
      "Epoch 642/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 554.8143 - val_loss: 4494.2295\n",
      "Epoch 643/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 543.1538 - val_loss: 5958.3130\n",
      "Epoch 644/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 599.1319 - val_loss: 4861.0830\n",
      "Epoch 645/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 586.0253 - val_loss: 4489.0654\n",
      "Epoch 646/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 515.8410 - val_loss: 7053.8979\n",
      "Epoch 647/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 549.6866 - val_loss: 5433.8472\n",
      "Epoch 648/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 478.6444 - val_loss: 5093.0903\n",
      "Epoch 649/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 488.7536 - val_loss: 4767.6875\n",
      "Epoch 650/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 693.5139 - val_loss: 5269.1987\n",
      "Epoch 651/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 545.2778 - val_loss: 5290.6904\n",
      "Epoch 652/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 516.2642 - val_loss: 6481.5361\n",
      "Epoch 653/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 530.3779 - val_loss: 3279.7419\n",
      "Epoch 654/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 531.3917 - val_loss: 5537.9521\n",
      "Epoch 655/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 534.9470 - val_loss: 4303.8652\n",
      "Epoch 656/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 433.3546 - val_loss: 6114.0708\n",
      "Epoch 657/1500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 470.0943 - val_loss: 5727.2354\n",
      "Epoch 658/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 545.8691 - val_loss: 6887.1646\n",
      "Epoch 659/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 467.1348 - val_loss: 3279.5283\n",
      "Epoch 660/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 565.9529 - val_loss: 4947.2861\n",
      "Epoch 661/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 482.3934 - val_loss: 2846.3667\n",
      "Epoch 662/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 462.3536 - val_loss: 4513.1055\n",
      "Epoch 663/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 416.8311 - val_loss: 3752.6179\n",
      "Epoch 664/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 538.0854 - val_loss: 6516.1333\n",
      "Epoch 665/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 584.6376 - val_loss: 3147.5166\n",
      "Epoch 666/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 462.0770 - val_loss: 6133.9092\n",
      "Epoch 667/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 464.4183 - val_loss: 6539.4937\n",
      "Epoch 668/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 419.8602 - val_loss: 5536.1636\n",
      "Epoch 669/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 498.2157 - val_loss: 4028.4290\n",
      "Epoch 670/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 511.0494 - val_loss: 6856.7812\n",
      "Epoch 671/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 476.7135 - val_loss: 4632.8281\n",
      "Epoch 672/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 535.1843 - val_loss: 6591.0518\n",
      "Epoch 673/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 545.3621 - val_loss: 4392.9629\n",
      "Epoch 674/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 430.6381 - val_loss: 5546.7563\n",
      "Epoch 675/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 440.1914 - val_loss: 6789.3047\n",
      "Epoch 676/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 401.9424 - val_loss: 5718.6582\n",
      "Epoch 677/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 450.9430 - val_loss: 6823.5840\n",
      "Epoch 678/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 388.4722 - val_loss: 5347.4263\n",
      "Epoch 679/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 426.7420 - val_loss: 3373.9375\n",
      "Epoch 680/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 445.3688 - val_loss: 6081.6016\n",
      "Epoch 681/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 439.4249 - val_loss: 5581.2417\n",
      "Epoch 682/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 444.5575 - val_loss: 4860.5615\n",
      "Epoch 683/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 454.0499 - val_loss: 4001.8713\n",
      "Epoch 684/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 424.5915 - val_loss: 6073.4434\n",
      "Epoch 685/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 450.7660 - val_loss: 4647.4170\n",
      "Epoch 686/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 445.6406 - val_loss: 4546.5977\n",
      "Epoch 687/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 424.5212 - val_loss: 5269.0210\n",
      "Epoch 688/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 407.9484 - val_loss: 4155.3301\n",
      "Epoch 689/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 394.1220 - val_loss: 6421.0708\n",
      "Epoch 690/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 441.1826 - val_loss: 7235.4204\n",
      "Epoch 691/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 434.4751 - val_loss: 3526.0498\n",
      "Epoch 692/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 427.8680 - val_loss: 3854.5469\n",
      "Epoch 693/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 444.3928 - val_loss: 5383.2661\n",
      "Epoch 694/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 418.3421 - val_loss: 4106.0571\n",
      "Epoch 695/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 469.3417 - val_loss: 7255.6479\n",
      "Epoch 696/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 532.5369 - val_loss: 6008.7251\n",
      "Epoch 697/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 425.4243 - val_loss: 5692.5488\n",
      "Epoch 698/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 441.0181 - val_loss: 6608.0952\n",
      "Epoch 699/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 396.1448 - val_loss: 6448.3223\n",
      "Epoch 700/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 403.3576 - val_loss: 4978.1387\n",
      "Epoch 701/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 438.6773 - val_loss: 4534.6543\n",
      "Epoch 702/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 374.6695 - val_loss: 7564.0781\n",
      "Epoch 703/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 425.1603 - val_loss: 5671.6309\n",
      "Epoch 704/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 421.8091 - val_loss: 4584.7896\n",
      "Epoch 705/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 415.8173 - val_loss: 5564.2700\n",
      "Epoch 706/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 455.9199 - val_loss: 5662.2729\n",
      "Epoch 707/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 593.5294 - val_loss: 6652.7520\n",
      "Epoch 708/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 480.4748 - val_loss: 6478.5845\n",
      "Epoch 709/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 405.2556 - val_loss: 5673.5239\n",
      "Epoch 710/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 423.3429 - val_loss: 5494.7832\n",
      "Epoch 711/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 452.8573 - val_loss: 4456.5215\n",
      "Epoch 712/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 414.2424 - val_loss: 7656.4512\n",
      "Epoch 713/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 358.3712 - val_loss: 7417.2515\n",
      "Epoch 714/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 413.5798 - val_loss: 5358.4551\n",
      "Epoch 715/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 398.1498 - val_loss: 6467.9771\n",
      "Epoch 716/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 387.8214 - val_loss: 5017.6748\n",
      "Epoch 717/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 372.7899 - val_loss: 5477.2544\n",
      "Epoch 718/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 403.5618 - val_loss: 5235.0518\n",
      "Epoch 719/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 359.3904 - val_loss: 4562.8501\n",
      "Epoch 720/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 371.3515 - val_loss: 4479.1304\n",
      "Epoch 721/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 358.3008 - val_loss: 6609.4312\n",
      "Epoch 722/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 394.4932 - val_loss: 6806.2559\n",
      "Epoch 723/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 393.1625 - val_loss: 5843.5391\n",
      "Epoch 724/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 386.6792 - val_loss: 7386.5513\n",
      "Epoch 725/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 367.7164 - val_loss: 7330.3550\n",
      "Epoch 726/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 448.2731 - val_loss: 6333.6309\n",
      "Epoch 727/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 393.6766 - val_loss: 6832.4878\n",
      "Epoch 728/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 386.0635 - val_loss: 6139.3833\n",
      "Epoch 729/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 403.1227 - val_loss: 3977.3796\n",
      "Epoch 730/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 349.6229 - val_loss: 7695.4546\n",
      "Epoch 731/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 432.6822 - val_loss: 3921.2905\n",
      "Epoch 732/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 355.1947 - val_loss: 6686.9502\n",
      "Epoch 733/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 342.1650 - val_loss: 7229.2637\n",
      "Epoch 734/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 368.5788 - val_loss: 6327.3872\n",
      "Epoch 735/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 468.0962 - val_loss: 6980.1519\n",
      "Epoch 736/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 420.2239 - val_loss: 4938.4614\n",
      "Epoch 737/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 429.4738 - val_loss: 5472.7925\n",
      "Epoch 738/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 366.3041 - val_loss: 7544.8501\n",
      "Epoch 739/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 361.9853 - val_loss: 5468.9316\n",
      "Epoch 740/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 362.0683 - val_loss: 6748.8799\n",
      "Epoch 741/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 344.6299 - val_loss: 5132.3599\n",
      "Epoch 742/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 384.6817 - val_loss: 8379.0029\n",
      "Epoch 743/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 5ms/step - loss: 356.1393 - val_loss: 5759.7153\n",
      "Epoch 744/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 354.2803 - val_loss: 4774.7427\n",
      "Epoch 745/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 410.8097 - val_loss: 5412.6250\n",
      "Epoch 746/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 346.0889 - val_loss: 5833.6362\n",
      "Epoch 747/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 439.0398 - val_loss: 5087.8643\n",
      "Epoch 748/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 376.3182 - val_loss: 5654.0249\n",
      "Epoch 749/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 373.2917 - val_loss: 7306.6675\n",
      "Epoch 750/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 366.5778 - val_loss: 6669.5908\n",
      "Epoch 751/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 366.2167 - val_loss: 5273.6543\n",
      "Epoch 752/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 354.5467 - val_loss: 5351.2749\n",
      "Epoch 753/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 420.4445 - val_loss: 6876.6812\n",
      "Epoch 754/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 360.0392 - val_loss: 4305.4004\n",
      "Epoch 755/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 304.6044 - val_loss: 8562.5898\n",
      "Epoch 756/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 335.6345 - val_loss: 4962.6440\n",
      "Epoch 757/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 335.6936 - val_loss: 5915.2642\n",
      "Epoch 758/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 424.4806 - val_loss: 7963.8013\n",
      "Epoch 759/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 400.0532 - val_loss: 5809.3892\n",
      "Epoch 760/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 342.6001 - val_loss: 5325.7974\n",
      "Epoch 761/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 388.8984 - val_loss: 3870.6492\n",
      "Epoch 762/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 347.9730 - val_loss: 6161.7612\n",
      "Epoch 763/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 319.7894 - val_loss: 6198.0845\n",
      "Epoch 764/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 306.8339 - val_loss: 6540.4702\n",
      "Epoch 765/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 467.5728 - val_loss: 7963.6108\n",
      "Epoch 766/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 396.1420 - val_loss: 4551.6309\n",
      "Epoch 767/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 375.9205 - val_loss: 5315.0713\n",
      "Epoch 768/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 385.1522 - val_loss: 7087.9971\n",
      "Epoch 769/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 375.5823 - val_loss: 8083.2031\n",
      "Epoch 770/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 324.9845 - val_loss: 6201.8721\n",
      "Epoch 771/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 304.6125 - val_loss: 4944.8721\n",
      "Epoch 772/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 311.7114 - val_loss: 7510.4424\n",
      "Epoch 773/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 481.3323 - val_loss: 4604.2065\n",
      "Epoch 774/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 353.0773 - val_loss: 4952.1270\n",
      "Epoch 775/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 344.4323 - val_loss: 7978.5630\n",
      "Epoch 776/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 336.1311 - val_loss: 5115.7988\n",
      "Epoch 777/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 349.4378 - val_loss: 5563.6079\n",
      "Epoch 778/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 404.6957 - val_loss: 5200.8174\n",
      "Epoch 779/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 338.8245 - val_loss: 5195.6152\n",
      "Epoch 780/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 336.8329 - val_loss: 6559.0918\n",
      "Epoch 781/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 539.9032 - val_loss: 4833.3677\n",
      "Epoch 782/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 454.2125 - val_loss: 5900.5225\n",
      "Epoch 783/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 425.6120 - val_loss: 4682.4966\n",
      "Epoch 784/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 459.7892 - val_loss: 5440.0342\n",
      "Epoch 785/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 333.7857 - val_loss: 3539.0227\n",
      "Epoch 786/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 430.1187 - val_loss: 6713.4438\n",
      "Epoch 787/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 408.3836 - val_loss: 4763.0215\n",
      "Epoch 788/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 378.8942 - val_loss: 7098.8906\n",
      "Epoch 789/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 346.4551 - val_loss: 4562.6831\n",
      "Epoch 790/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 414.6931 - val_loss: 4812.5894\n",
      "Epoch 791/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 342.2041 - val_loss: 7639.7217\n",
      "Epoch 792/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 381.7590 - val_loss: 4219.4873\n",
      "Epoch 793/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 402.3492 - val_loss: 6027.9277\n",
      "Epoch 794/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 409.0307 - val_loss: 9489.3311\n",
      "Epoch 795/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 328.3095 - val_loss: 4508.0811\n",
      "Epoch 796/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 315.6861 - val_loss: 6002.6245\n",
      "Epoch 797/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 408.1074 - val_loss: 5637.7617\n",
      "Epoch 798/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 402.2124 - val_loss: 5743.2646\n",
      "Epoch 799/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 383.8410 - val_loss: 6766.4800\n",
      "Epoch 800/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 400.3372 - val_loss: 6978.1377\n",
      "Epoch 801/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 339.5896 - val_loss: 6312.2144\n",
      "Epoch 802/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 354.2196 - val_loss: 4677.2422\n",
      "Epoch 803/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 384.1459 - val_loss: 5423.5454\n",
      "Epoch 804/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 409.6304 - val_loss: 6706.3281\n",
      "Epoch 805/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 396.2408 - val_loss: 4391.6855\n",
      "Epoch 806/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 336.6307 - val_loss: 5325.0420\n",
      "Epoch 807/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 345.5653 - val_loss: 7502.5405\n",
      "Epoch 808/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 413.3860 - val_loss: 8405.2412\n",
      "Epoch 809/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 379.9795 - val_loss: 3501.1584\n",
      "Epoch 810/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 326.0348 - val_loss: 3719.3921\n",
      "Epoch 811/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 362.3811 - val_loss: 7959.2612\n",
      "Epoch 812/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 339.2411 - val_loss: 5356.4165\n",
      "Epoch 813/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 347.3171 - val_loss: 6806.6592\n",
      "Epoch 814/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 324.4989 - val_loss: 5030.6060\n",
      "Epoch 815/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 367.6703 - val_loss: 4962.8535\n",
      "Epoch 816/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 311.2958 - val_loss: 5605.2212\n",
      "Epoch 817/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 332.0727 - val_loss: 5432.4575\n",
      "Epoch 818/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 356.7355 - val_loss: 7638.4331\n",
      "Epoch 819/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 326.5761 - val_loss: 7711.5190\n",
      "Epoch 820/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 374.2688 - val_loss: 6318.2246\n",
      "Epoch 821/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 343.5715 - val_loss: 4776.8013\n",
      "Epoch 822/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 364.6577 - val_loss: 6989.8354\n",
      "Epoch 823/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 300.8340 - val_loss: 6265.7188\n",
      "Epoch 824/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 283.9040 - val_loss: 6137.8452\n",
      "Epoch 825/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 327.1996 - val_loss: 5914.5410\n",
      "Epoch 826/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 319.4477 - val_loss: 4602.0562\n",
      "Epoch 827/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 383.4442 - val_loss: 6066.4253\n",
      "Epoch 828/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 374.5390 - val_loss: 4628.2622\n",
      "Epoch 829/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 342.2515 - val_loss: 6557.6548\n",
      "Epoch 830/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 311.3646 - val_loss: 5122.1577\n",
      "Epoch 831/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 311.0180 - val_loss: 8205.3877\n",
      "Epoch 832/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 301.0915 - val_loss: 4954.8789\n",
      "Epoch 833/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 323.0334 - val_loss: 4941.4233\n",
      "Epoch 834/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 309.3609 - val_loss: 7463.6958\n",
      "Epoch 835/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 332.9216 - val_loss: 5109.4141\n",
      "Epoch 836/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 330.0292 - val_loss: 7049.8125\n",
      "Epoch 837/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 317.4567 - val_loss: 7166.9033\n",
      "Epoch 838/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 302.0048 - val_loss: 4889.0957\n",
      "Epoch 839/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 321.2058 - val_loss: 5540.9536\n",
      "Epoch 840/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 320.6996 - val_loss: 6914.3535\n",
      "Epoch 841/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 319.3654 - val_loss: 5526.5425\n",
      "Epoch 842/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 350.0505 - val_loss: 6631.5498\n",
      "Epoch 843/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 336.3770 - val_loss: 5917.7949\n",
      "Epoch 844/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 398.1715 - val_loss: 6295.0732\n",
      "Epoch 845/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 357.2007 - val_loss: 9987.7695\n",
      "Epoch 846/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 328.9383 - val_loss: 7652.8872\n",
      "Epoch 847/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 315.5501 - val_loss: 4549.6191\n",
      "Epoch 848/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 343.7466 - val_loss: 6421.9717\n",
      "Epoch 849/1500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 357.2431 - val_loss: 5200.1177\n",
      "Epoch 850/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 431.4664 - val_loss: 6327.1504\n",
      "Epoch 851/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 260.6118 - val_loss: 5887.6948\n",
      "Epoch 852/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 297.0098 - val_loss: 6371.5503\n",
      "Epoch 853/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 321.8345 - val_loss: 4948.4536\n",
      "Epoch 854/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 306.0747 - val_loss: 5661.5068\n",
      "Epoch 855/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 338.2440 - val_loss: 6592.5308\n",
      "Epoch 856/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 335.2959 - val_loss: 5466.6938\n",
      "Epoch 857/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 340.5912 - val_loss: 5372.9380\n",
      "Epoch 858/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 301.4242 - val_loss: 5133.4580\n",
      "Epoch 859/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 345.3507 - val_loss: 7185.1108\n",
      "Epoch 860/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 334.2102 - val_loss: 7652.0161\n",
      "Epoch 861/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 368.5063 - val_loss: 5864.7935\n",
      "Epoch 862/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 378.4345 - val_loss: 6420.6675\n",
      "Epoch 863/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 305.2899 - val_loss: 8760.4102\n",
      "Epoch 864/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 361.2522 - val_loss: 5963.0767\n",
      "Epoch 865/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 299.6703 - val_loss: 5326.4600\n",
      "Epoch 866/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 374.4935 - val_loss: 5417.7051\n",
      "Epoch 867/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 312.7224 - val_loss: 7141.0908\n",
      "Epoch 868/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 278.8449 - val_loss: 5917.7153\n",
      "Epoch 869/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 414.7068 - val_loss: 6223.1753\n",
      "Epoch 870/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 361.0499 - val_loss: 8376.8652\n",
      "Epoch 871/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 330.5252 - val_loss: 5971.0796\n",
      "Epoch 872/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 364.3823 - val_loss: 5432.0938\n",
      "Epoch 873/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 295.8917 - val_loss: 5095.1318\n",
      "Epoch 874/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 290.2947 - val_loss: 5975.9595\n",
      "Epoch 875/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 301.3179 - val_loss: 6819.6392\n",
      "Epoch 876/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 294.2711 - val_loss: 4283.1592\n",
      "Epoch 877/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 311.0304 - val_loss: 7057.1904\n",
      "Epoch 878/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 335.6897 - val_loss: 5861.7183\n",
      "Epoch 879/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 329.5896 - val_loss: 7654.0786\n",
      "Epoch 880/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 332.7902 - val_loss: 8889.5195\n",
      "Epoch 881/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 303.0458 - val_loss: 5752.1309\n",
      "Epoch 882/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 293.0613 - val_loss: 6358.2896\n",
      "Epoch 883/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 311.6001 - val_loss: 6096.0708\n",
      "Epoch 884/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 315.1911 - val_loss: 5969.1948\n",
      "Epoch 885/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 356.0141 - val_loss: 4952.6519\n",
      "Epoch 886/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 326.2084 - val_loss: 5109.7310\n",
      "Epoch 887/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 385.4948 - val_loss: 5991.3706\n",
      "Epoch 888/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 299.6728 - val_loss: 7061.8691\n",
      "Epoch 889/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 298.7958 - val_loss: 4862.9531\n",
      "Epoch 890/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 295.1196 - val_loss: 6941.2783\n",
      "Epoch 891/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 316.9442 - val_loss: 6837.9761\n",
      "Epoch 892/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 303.3669 - val_loss: 4984.1284\n",
      "Epoch 893/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 290.6637 - val_loss: 6433.7598\n",
      "Epoch 894/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 288.4533 - val_loss: 4971.2529\n",
      "Epoch 895/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 262.5152 - val_loss: 5058.6187\n",
      "Epoch 896/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 285.7329 - val_loss: 6381.6953\n",
      "Epoch 897/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 278.8452 - val_loss: 5949.5269\n",
      "Epoch 898/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 299.1622 - val_loss: 4860.3950\n",
      "Epoch 899/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 294.5995 - val_loss: 5175.3071\n",
      "Epoch 900/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 294.2600 - val_loss: 8156.9614\n",
      "Epoch 901/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 388.6644 - val_loss: 5296.2378\n",
      "Epoch 902/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 310.2596 - val_loss: 4581.3892\n",
      "Epoch 903/1500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 304.3968 - val_loss: 5496.2910\n",
      "Epoch 904/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 318.5743 - val_loss: 7572.2217\n",
      "Epoch 905/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 264.3567 - val_loss: 7796.1748\n",
      "Epoch 906/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 287.1329 - val_loss: 6664.3218\n",
      "Epoch 907/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 262.6382 - val_loss: 6603.0073\n",
      "Epoch 908/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 319.5129 - val_loss: 4739.9121\n",
      "Epoch 909/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 305.0172 - val_loss: 7101.6187\n",
      "Epoch 910/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 331.2717 - val_loss: 6575.9980\n",
      "Epoch 911/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 346.1676 - val_loss: 3713.3047\n",
      "Epoch 912/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 332.2999 - val_loss: 5685.1187\n",
      "Epoch 913/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 263.3942 - val_loss: 4383.2563\n",
      "Epoch 914/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 257.5614 - val_loss: 4325.3906\n",
      "Epoch 915/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 303.7663 - val_loss: 7856.0581\n",
      "Epoch 916/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 313.3813 - val_loss: 4322.9224\n",
      "Epoch 917/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 359.8629 - val_loss: 6294.8750\n",
      "Epoch 918/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 256.8240 - val_loss: 6128.3857\n",
      "Epoch 919/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 270.2730 - val_loss: 6339.7422\n",
      "Epoch 920/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 313.9138 - val_loss: 4789.3364\n",
      "Epoch 921/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 272.6651 - val_loss: 6679.6611\n",
      "Epoch 922/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 342.4495 - val_loss: 6376.2793\n",
      "Epoch 923/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 266.5516 - val_loss: 6322.1035\n",
      "Epoch 924/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 317.3922 - val_loss: 4572.9702\n",
      "Epoch 925/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 313.6916 - val_loss: 5528.9448\n",
      "Epoch 926/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 301.2039 - val_loss: 5073.8950\n",
      "Epoch 927/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 290.4189 - val_loss: 8384.8545\n",
      "Epoch 928/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 315.3701 - val_loss: 6661.1738\n",
      "Epoch 929/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 327.0098 - val_loss: 4571.2676\n",
      "Epoch 930/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 261.9620 - val_loss: 3637.9431\n",
      "Epoch 931/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 287.7861 - val_loss: 7489.4771\n",
      "Epoch 932/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 262.5642 - val_loss: 5096.6753\n",
      "Epoch 933/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 270.0970 - val_loss: 8477.0234\n",
      "Epoch 934/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 264.7688 - val_loss: 5503.5371\n",
      "Epoch 935/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 268.8332 - val_loss: 6065.7729\n",
      "Epoch 936/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 321.9408 - val_loss: 6011.4844\n",
      "Epoch 937/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 295.9003 - val_loss: 5334.2700\n",
      "Epoch 938/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 287.4352 - val_loss: 5258.7236\n",
      "Epoch 939/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 285.3293 - val_loss: 6856.2441\n",
      "Epoch 940/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 288.0379 - val_loss: 6421.1660\n",
      "Epoch 941/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 298.5287 - val_loss: 8200.3066\n",
      "Epoch 942/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 298.5167 - val_loss: 6196.8770\n",
      "Epoch 943/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 326.5285 - val_loss: 5063.9785\n",
      "Epoch 944/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 344.8561 - val_loss: 6240.8877\n",
      "Epoch 945/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 324.6811 - val_loss: 6924.4702\n",
      "Epoch 946/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 299.5817 - val_loss: 3745.9688\n",
      "Epoch 947/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 393.5674 - val_loss: 6329.5234\n",
      "Epoch 948/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 350.5410 - val_loss: 7341.7544\n",
      "Epoch 949/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 306.7323 - val_loss: 6203.4731\n",
      "Epoch 950/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 312.8762 - val_loss: 6162.0625\n",
      "Epoch 951/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 342.6357 - val_loss: 7492.8423\n",
      "Epoch 952/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 284.2823 - val_loss: 5765.8169\n",
      "Epoch 953/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 324.8111 - val_loss: 4388.1313\n",
      "Epoch 954/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 301.6091 - val_loss: 7193.6357\n",
      "Epoch 955/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 305.4550 - val_loss: 6076.3159\n",
      "Epoch 956/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 350.1058 - val_loss: 7819.6250\n",
      "Epoch 957/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 294.7983 - val_loss: 7343.4390\n",
      "Epoch 958/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 304.5522 - val_loss: 6328.2451\n",
      "Epoch 959/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 296.8695 - val_loss: 6246.0986\n",
      "Epoch 960/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 275.9824 - val_loss: 4929.0239\n",
      "Epoch 961/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 325.5952 - val_loss: 5166.8247\n",
      "Epoch 962/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 302.3524 - val_loss: 6456.3638\n",
      "Epoch 963/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 316.8648 - val_loss: 10579.8838\n",
      "Epoch 964/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 342.0771 - val_loss: 7434.2739\n",
      "Epoch 965/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 302.0475 - val_loss: 8948.4941\n",
      "Epoch 966/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 309.5772 - val_loss: 6676.6562\n",
      "Epoch 967/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 324.9674 - val_loss: 10111.7314\n",
      "Epoch 968/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 328.1610 - val_loss: 4912.5542\n",
      "Epoch 969/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 259.8235 - val_loss: 6076.6924\n",
      "Epoch 970/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 296.4875 - val_loss: 4575.1777\n",
      "Epoch 971/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 301.8662 - val_loss: 4977.2246\n",
      "Epoch 972/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 341.0030 - val_loss: 6870.4482\n",
      "Epoch 973/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 380.0203 - val_loss: 7207.2246\n",
      "Epoch 974/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 270.3626 - val_loss: 7318.1909\n",
      "Epoch 975/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 329.0887 - val_loss: 4050.5376\n",
      "Epoch 976/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 301.1855 - val_loss: 6382.9907\n",
      "Epoch 977/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 309.2464 - val_loss: 4976.1401\n",
      "Epoch 978/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 296.2239 - val_loss: 7893.6265\n",
      "Epoch 979/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 321.8094 - val_loss: 4703.5356\n",
      "Epoch 980/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 293.1701 - val_loss: 5901.5874\n",
      "Epoch 981/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 308.4301 - val_loss: 5734.6934\n",
      "Epoch 982/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 303.9336 - val_loss: 6438.8003\n",
      "Epoch 983/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 290.2824 - val_loss: 5018.4043\n",
      "Epoch 984/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 291.2322 - val_loss: 4984.9565\n",
      "Epoch 985/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 272.2277 - val_loss: 8026.1323\n",
      "Epoch 986/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 292.4620 - val_loss: 5854.0405\n",
      "Epoch 987/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 301.3923 - val_loss: 5343.9106\n",
      "Epoch 988/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 276.8365 - val_loss: 4680.6689\n",
      "Epoch 989/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 301.1198 - val_loss: 5917.6777\n",
      "Epoch 990/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 293.6533 - val_loss: 5182.7056\n",
      "Epoch 991/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 305.8093 - val_loss: 10271.2842\n",
      "Epoch 992/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 306.8913 - val_loss: 5124.7246\n",
      "Epoch 993/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 279.3414 - val_loss: 7152.8027\n",
      "Epoch 994/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 350.3662 - val_loss: 4317.7612\n",
      "Epoch 995/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 289.8608 - val_loss: 5158.7939\n",
      "Epoch 996/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 266.9751 - val_loss: 4657.7661\n",
      "Epoch 997/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 312.4431 - val_loss: 5023.7271\n",
      "Epoch 998/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 307.5279 - val_loss: 3678.9392\n",
      "Epoch 999/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 319.2124 - val_loss: 7028.4590\n",
      "Epoch 1000/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 321.3631 - val_loss: 5120.5708\n",
      "Epoch 1001/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 337.8520 - val_loss: 5454.5269\n",
      "Epoch 1002/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 300.4024 - val_loss: 5439.7480\n",
      "Epoch 1003/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 298.2003 - val_loss: 7111.1333\n",
      "Epoch 1004/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 325.7313 - val_loss: 3823.8916\n",
      "Epoch 1005/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 355.3767 - val_loss: 5120.7515\n",
      "Epoch 1006/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 291.3356 - val_loss: 6496.7114\n",
      "Epoch 1007/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 263.2508 - val_loss: 5031.2676\n",
      "Epoch 1008/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 338.8853 - val_loss: 5862.4771\n",
      "Epoch 1009/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 254.0827 - val_loss: 5313.9604\n",
      "Epoch 1010/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 270.5106 - val_loss: 7248.0410\n",
      "Epoch 1011/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 271.8367 - val_loss: 5599.6245\n",
      "Epoch 1012/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 317.9265 - val_loss: 7360.1333\n",
      "Epoch 1013/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 267.2119 - val_loss: 7266.8379\n",
      "Epoch 1014/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 324.4452 - val_loss: 6547.4121\n",
      "Epoch 1015/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 251.3071 - val_loss: 3631.2849\n",
      "Epoch 1016/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 302.6175 - val_loss: 4547.0317\n",
      "Epoch 1017/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 311.4821 - val_loss: 5499.9097\n",
      "Epoch 1018/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 257.1054 - val_loss: 8247.3281\n",
      "Epoch 1019/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 294.6382 - val_loss: 6325.5044\n",
      "Epoch 1020/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 284.4397 - val_loss: 5678.6890\n",
      "Epoch 1021/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 313.0290 - val_loss: 8271.3096\n",
      "Epoch 1022/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 341.5827 - val_loss: 6506.8174\n",
      "Epoch 1023/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 319.5187 - val_loss: 6089.0542\n",
      "Epoch 1024/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 256.7361 - val_loss: 6518.1284\n",
      "Epoch 1025/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 364.5866 - val_loss: 4375.1055\n",
      "Epoch 1026/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 263.3144 - val_loss: 9030.0098\n",
      "Epoch 1027/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 317.7476 - val_loss: 5598.5435\n",
      "Epoch 1028/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 281.4396 - val_loss: 6016.5425\n",
      "Epoch 1029/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 263.5723 - val_loss: 6396.7427\n",
      "Epoch 1030/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 286.3421 - val_loss: 7182.7261\n",
      "Epoch 1031/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 362.6147 - val_loss: 5048.6270\n",
      "Epoch 1032/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 306.2240 - val_loss: 9939.6094\n",
      "Epoch 1033/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 353.6176 - val_loss: 6046.5513\n",
      "Epoch 1034/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 306.7118 - val_loss: 6264.4546\n",
      "Epoch 1035/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 261.8349 - val_loss: 5471.2144\n",
      "Epoch 1036/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.4860 - val_loss: 6258.4839\n",
      "Epoch 1037/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 270.9273 - val_loss: 4993.4927\n",
      "Epoch 1038/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 265.0526 - val_loss: 4650.0234\n",
      "Epoch 1039/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 345.1987 - val_loss: 6011.3877\n",
      "Epoch 1040/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 294.5548 - val_loss: 6033.2612\n",
      "Epoch 1041/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 288.0922 - val_loss: 8712.2607\n",
      "Epoch 1042/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 340.8083 - val_loss: 7398.2598\n",
      "Epoch 1043/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 281.7404 - val_loss: 6410.8848\n",
      "Epoch 1044/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 323.6059 - val_loss: 5712.8384\n",
      "Epoch 1045/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 290.7714 - val_loss: 7185.7217\n",
      "Epoch 1046/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 301.5482 - val_loss: 7134.7598\n",
      "Epoch 1047/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 273.0743 - val_loss: 4824.6406\n",
      "Epoch 1048/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 302.8642 - val_loss: 5705.9619\n",
      "Epoch 1049/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 268.9596 - val_loss: 5531.8979\n",
      "Epoch 1050/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 268.4677 - val_loss: 8157.0425\n",
      "Epoch 1051/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 276.7411 - val_loss: 7993.7217\n",
      "Epoch 1052/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 290.2220 - val_loss: 7887.5083\n",
      "Epoch 1053/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 284.7064 - val_loss: 7223.6592\n",
      "Epoch 1054/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 276.8971 - val_loss: 7298.7471\n",
      "Epoch 1055/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 259.0322 - val_loss: 7629.1738\n",
      "Epoch 1056/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 306.0348 - val_loss: 5290.7524\n",
      "Epoch 1057/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 272.4595 - val_loss: 6034.4922\n",
      "Epoch 1058/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 299.6855 - val_loss: 7956.3496\n",
      "Epoch 1059/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 303.5004 - val_loss: 5716.5952\n",
      "Epoch 1060/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 308.3461 - val_loss: 5854.4243\n",
      "Epoch 1061/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 278.2992 - val_loss: 4216.7817\n",
      "Epoch 1062/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 269.3440 - val_loss: 5986.4922\n",
      "Epoch 1063/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 280.5738 - val_loss: 6851.1406\n",
      "Epoch 1064/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 354.6924 - val_loss: 5208.7207\n",
      "Epoch 1065/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 300.6653 - val_loss: 7846.7559\n",
      "Epoch 1066/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 284.0158 - val_loss: 4745.1880\n",
      "Epoch 1067/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 299.3862 - val_loss: 6449.5386\n",
      "Epoch 1068/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 275.6423 - val_loss: 6432.0513\n",
      "Epoch 1069/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 291.4176 - val_loss: 4157.0391\n",
      "Epoch 1070/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 291.4618 - val_loss: 6644.3486\n",
      "Epoch 1071/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 288.5810 - val_loss: 5116.5942\n",
      "Epoch 1072/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 343.8470 - val_loss: 5440.8926\n",
      "Epoch 1073/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 286.2546 - val_loss: 7746.2969\n",
      "Epoch 1074/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 330.1062 - val_loss: 4900.3481\n",
      "Epoch 1075/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 286.6286 - val_loss: 7578.6562\n",
      "Epoch 1076/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.2468 - val_loss: 5586.9043\n",
      "Epoch 1077/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 327.8883 - val_loss: 6096.1123\n",
      "Epoch 1078/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 314.6172 - val_loss: 5917.9478\n",
      "Epoch 1079/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 296.6564 - val_loss: 5611.8760\n",
      "Epoch 1080/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 338.5926 - val_loss: 7002.9941\n",
      "Epoch 1081/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 300.8102 - val_loss: 4053.8867\n",
      "Epoch 1082/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 250.9052 - val_loss: 5996.9185\n",
      "Epoch 1083/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 323.6563 - val_loss: 5451.6875\n",
      "Epoch 1084/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 283.6356 - val_loss: 8014.8657\n",
      "Epoch 1085/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 294.2827 - val_loss: 5687.3936\n",
      "Epoch 1086/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 323.9094 - val_loss: 6026.2246\n",
      "Epoch 1087/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 262.8451 - val_loss: 9880.7764\n",
      "Epoch 1088/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 310.1867 - val_loss: 7277.6675\n",
      "Epoch 1089/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 346.0108 - val_loss: 5523.0723\n",
      "Epoch 1090/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 277.7600 - val_loss: 9045.8867\n",
      "Epoch 1091/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 286.0922 - val_loss: 5045.8198\n",
      "Epoch 1092/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 279.5363 - val_loss: 3340.1064\n",
      "Epoch 1093/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 282.6435 - val_loss: 4229.7188\n",
      "Epoch 1094/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 301.2068 - val_loss: 5226.5947\n",
      "Epoch 1095/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 344.7708 - val_loss: 6227.4800\n",
      "Epoch 1096/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 283.7282 - val_loss: 6199.8511\n",
      "Epoch 1097/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 274.2033 - val_loss: 3774.6482\n",
      "Epoch 1098/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 310.6287 - val_loss: 6414.0659\n",
      "Epoch 1099/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 314.0784 - val_loss: 5427.3872\n",
      "Epoch 1100/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 289.3625 - val_loss: 5938.9048\n",
      "Epoch 1101/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 300.1793 - val_loss: 6618.8911\n",
      "Epoch 1102/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 321.2939 - val_loss: 9458.3945\n",
      "Epoch 1103/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 340.2756 - val_loss: 5344.2144\n",
      "Epoch 1104/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 301.7295 - val_loss: 6258.0776\n",
      "Epoch 1105/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 283.2724 - val_loss: 6218.7300\n",
      "Epoch 1106/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 276.0193 - val_loss: 6422.5752\n",
      "Epoch 1107/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 352.6027 - val_loss: 5248.4160\n",
      "Epoch 1108/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 360.2187 - val_loss: 3478.4719\n",
      "Epoch 1109/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 301.7697 - val_loss: 5620.4219\n",
      "Epoch 1110/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 276.1996 - val_loss: 6589.9014\n",
      "Epoch 1111/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 309.3015 - val_loss: 6447.9927\n",
      "Epoch 1112/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 257.2029 - val_loss: 3868.2585\n",
      "Epoch 1113/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 270.5624 - val_loss: 5190.9395\n",
      "Epoch 1114/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 295.5420 - val_loss: 5218.7319\n",
      "Epoch 1115/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 288.2257 - val_loss: 4537.8232\n",
      "Epoch 1116/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 303.5562 - val_loss: 6862.9248\n",
      "Epoch 1117/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 283.4066 - val_loss: 7248.9653\n",
      "Epoch 1118/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 324.0761 - val_loss: 4758.2891\n",
      "Epoch 1119/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 312.1784 - val_loss: 4234.6738\n",
      "Epoch 1120/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 298.5053 - val_loss: 8986.5898\n",
      "Epoch 1121/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 289.2659 - val_loss: 7007.0723\n",
      "Epoch 1122/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 266.0129 - val_loss: 5450.6616\n",
      "Epoch 1123/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 5ms/step - loss: 285.8123 - val_loss: 10233.1367\n",
      "Epoch 1124/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 321.0769 - val_loss: 6746.1333\n",
      "Epoch 1125/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 291.7718 - val_loss: 6538.4434\n",
      "Epoch 1126/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 301.1293 - val_loss: 3749.6963\n",
      "Epoch 1127/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 322.1818 - val_loss: 4091.0203\n",
      "Epoch 1128/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 320.8801 - val_loss: 2951.7942\n",
      "Epoch 1129/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 284.2188 - val_loss: 7044.0317\n",
      "Epoch 1130/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 295.1175 - val_loss: 2997.1924\n",
      "Epoch 1131/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 290.2690 - val_loss: 7351.7231\n",
      "Epoch 1132/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 281.6335 - val_loss: 5025.6045\n",
      "Epoch 1133/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 293.3160 - val_loss: 4402.0576\n",
      "Epoch 1134/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 280.4900 - val_loss: 4572.6836\n",
      "Epoch 1135/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 282.5516 - val_loss: 7558.1802\n",
      "Epoch 1136/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 303.2439 - val_loss: 4511.8179\n",
      "Epoch 1137/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 268.2393 - val_loss: 6580.3672\n",
      "Epoch 1138/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 277.3104 - val_loss: 5714.6953\n",
      "Epoch 1139/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 281.8995 - val_loss: 7366.2349\n",
      "Epoch 1140/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 272.0821 - val_loss: 6001.0762\n",
      "Epoch 1141/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 299.7969 - val_loss: 6220.9263\n",
      "Epoch 1142/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 293.3507 - val_loss: 12841.1533\n",
      "Epoch 1143/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 274.0671 - val_loss: 5223.7261\n",
      "Epoch 1144/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.3143 - val_loss: 4545.5435\n",
      "Epoch 1145/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 271.5553 - val_loss: 7406.8623\n",
      "Epoch 1146/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 285.8043 - val_loss: 6370.8467\n",
      "Epoch 1147/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 294.5326 - val_loss: 4561.6177\n",
      "Epoch 1148/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.1877 - val_loss: 5939.2632\n",
      "Epoch 1149/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 262.1361 - val_loss: 6948.3564\n",
      "Epoch 1150/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 306.9942 - val_loss: 8442.3252\n",
      "Epoch 1151/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 280.3342 - val_loss: 5369.1621\n",
      "Epoch 1152/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.9736 - val_loss: 4301.9097\n",
      "Epoch 1153/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 294.8963 - val_loss: 5929.2705\n",
      "Epoch 1154/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 260.3613 - val_loss: 7233.1646\n",
      "Epoch 1155/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 312.6714 - val_loss: 6907.6060\n",
      "Epoch 1156/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 326.0936 - val_loss: 5422.3530\n",
      "Epoch 1157/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 283.7285 - val_loss: 5622.9829\n",
      "Epoch 1158/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 265.4404 - val_loss: 7367.8950\n",
      "Epoch 1159/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 303.6702 - val_loss: 6469.8003\n",
      "Epoch 1160/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 293.1028 - val_loss: 6346.6592\n",
      "Epoch 1161/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 260.2741 - val_loss: 10200.2041\n",
      "Epoch 1162/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 276.9565 - val_loss: 7282.6875\n",
      "Epoch 1163/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 264.4397 - val_loss: 6477.5391\n",
      "Epoch 1164/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 265.8140 - val_loss: 3857.4060\n",
      "Epoch 1165/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 338.6630 - val_loss: 5232.6938\n",
      "Epoch 1166/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 291.1746 - val_loss: 4394.7749\n",
      "Epoch 1167/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 326.7386 - val_loss: 7931.0854\n",
      "Epoch 1168/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 249.1576 - val_loss: 3829.1392\n",
      "Epoch 1169/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 316.6111 - val_loss: 6706.9019\n",
      "Epoch 1170/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 299.0773 - val_loss: 6507.1465\n",
      "Epoch 1171/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 290.4968 - val_loss: 6328.0234\n",
      "Epoch 1172/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 303.9618 - val_loss: 7813.5908\n",
      "Epoch 1173/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 338.2321 - val_loss: 5534.4731\n",
      "Epoch 1174/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 278.7973 - val_loss: 5255.6709\n",
      "Epoch 1175/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 309.3930 - val_loss: 7489.0361\n",
      "Epoch 1176/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 283.6145 - val_loss: 6108.2075\n",
      "Epoch 1177/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 286.9513 - val_loss: 5359.8887\n",
      "Epoch 1178/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 278.2632 - val_loss: 5886.9902\n",
      "Epoch 1179/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 278.3217 - val_loss: 7607.0488\n",
      "Epoch 1180/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.7829 - val_loss: 6629.9375\n",
      "Epoch 1181/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 261.9366 - val_loss: 7171.6177\n",
      "Epoch 1182/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 262.9722 - val_loss: 5218.1777\n",
      "Epoch 1183/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 278.9868 - val_loss: 5345.3169\n",
      "Epoch 1184/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 233.7936 - val_loss: 6368.5840\n",
      "Epoch 1185/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.9541 - val_loss: 5878.7231\n",
      "Epoch 1186/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 247.8335 - val_loss: 2677.4534\n",
      "Epoch 1187/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 312.0225 - val_loss: 5326.8892\n",
      "Epoch 1188/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 252.5117 - val_loss: 8748.0361\n",
      "Epoch 1189/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 302.4808 - val_loss: 3929.6677\n",
      "Epoch 1190/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 253.1010 - val_loss: 3279.5469\n",
      "Epoch 1191/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 276.9459 - val_loss: 7102.3423\n",
      "Epoch 1192/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 250.9202 - val_loss: 6684.0801\n",
      "Epoch 1193/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 301.0980 - val_loss: 7486.6846\n",
      "Epoch 1194/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 258.1097 - val_loss: 8258.0684\n",
      "Epoch 1195/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 302.9066 - val_loss: 11345.1660\n",
      "Epoch 1196/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 291.1502 - val_loss: 6539.6328\n",
      "Epoch 1197/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 233.6765 - val_loss: 7535.7871\n",
      "Epoch 1198/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 284.0781 - val_loss: 7824.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 298.2337 - val_loss: 3665.2698\n",
      "Epoch 1200/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 270.1458 - val_loss: 6654.8364\n",
      "Epoch 1201/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 247.9409 - val_loss: 7283.8765\n",
      "Epoch 1202/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 323.9807 - val_loss: 7718.8628\n",
      "Epoch 1203/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 263.1446 - val_loss: 3392.9819\n",
      "Epoch 1204/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 276.2853 - val_loss: 6501.1831\n",
      "Epoch 1205/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 258.7584 - val_loss: 5200.4497\n",
      "Epoch 1206/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 297.0437 - val_loss: 4532.7188\n",
      "Epoch 1207/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 248.2675 - val_loss: 6062.3940\n",
      "Epoch 1208/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 310.0036 - val_loss: 6471.3833\n",
      "Epoch 1209/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 266.5348 - val_loss: 6077.3833\n",
      "Epoch 1210/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 287.4536 - val_loss: 3532.1157\n",
      "Epoch 1211/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 267.5609 - val_loss: 5810.4082\n",
      "Epoch 1212/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 324.9848 - val_loss: 4470.7686\n",
      "Epoch 1213/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 337.4734 - val_loss: 8529.0029\n",
      "Epoch 1214/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 237.8305 - val_loss: 6755.9971\n",
      "Epoch 1215/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 268.0547 - val_loss: 5873.2271\n",
      "Epoch 1216/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 310.1190 - val_loss: 5517.7031\n",
      "Epoch 1217/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 332.2149 - val_loss: 7240.5410\n",
      "Epoch 1218/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 279.9042 - val_loss: 4703.2217\n",
      "Epoch 1219/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 307.3620 - val_loss: 6911.4316\n",
      "Epoch 1220/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 290.0538 - val_loss: 5215.9336\n",
      "Epoch 1221/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 308.9218 - val_loss: 7167.8936\n",
      "Epoch 1222/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 311.8742 - val_loss: 6160.2139\n",
      "Epoch 1223/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 270.0961 - val_loss: 8916.0420\n",
      "Epoch 1224/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 274.3796 - val_loss: 6356.5107\n",
      "Epoch 1225/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 305.9654 - val_loss: 5317.5439\n",
      "Epoch 1226/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 280.6667 - val_loss: 7623.3940\n",
      "Epoch 1227/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 299.8894 - val_loss: 7227.4331\n",
      "Epoch 1228/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 294.3914 - val_loss: 6354.2817\n",
      "Epoch 1229/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 260.1077 - val_loss: 3549.9211\n",
      "Epoch 1230/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 273.8435 - val_loss: 5901.6016\n",
      "Epoch 1231/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 317.2575 - val_loss: 6078.3232\n",
      "Epoch 1232/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 263.1056 - val_loss: 11373.9258\n",
      "Epoch 1233/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 237.1134 - val_loss: 5425.3042\n",
      "Epoch 1234/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 248.9427 - val_loss: 7649.1050\n",
      "Epoch 1235/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 300.5165 - val_loss: 3878.8516\n",
      "Epoch 1236/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 359.4353 - val_loss: 8188.5933\n",
      "Epoch 1237/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 320.5763 - val_loss: 4850.1948\n",
      "Epoch 1238/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 320.9058 - val_loss: 5314.9082\n",
      "Epoch 1239/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.4301 - val_loss: 5178.8423\n",
      "Epoch 1240/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 282.9656 - val_loss: 3071.9312\n",
      "Epoch 1241/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 272.1792 - val_loss: 6773.2793\n",
      "Epoch 1242/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 273.5245 - val_loss: 5635.9312\n",
      "Epoch 1243/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 282.9567 - val_loss: 4430.3198\n",
      "Epoch 1244/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 274.6023 - val_loss: 7881.5083\n",
      "Epoch 1245/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 261.9799 - val_loss: 7547.6323\n",
      "Epoch 1246/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 277.5060 - val_loss: 7508.9878\n",
      "Epoch 1247/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 266.7333 - val_loss: 4074.9561\n",
      "Epoch 1248/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 259.3878 - val_loss: 6000.8921\n",
      "Epoch 1249/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 239.9461 - val_loss: 6073.7720\n",
      "Epoch 1250/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 312.9742 - val_loss: 3731.7751\n",
      "Epoch 1251/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 244.6979 - val_loss: 3588.8440\n",
      "Epoch 1252/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 291.7689 - val_loss: 4892.1987\n",
      "Epoch 1253/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 240.6587 - val_loss: 6097.0278\n",
      "Epoch 1254/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 267.1518 - val_loss: 7053.2798\n",
      "Epoch 1255/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 262.9549 - val_loss: 6272.5171\n",
      "Epoch 1256/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 275.9607 - val_loss: 5790.0449\n",
      "Epoch 1257/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 266.4180 - val_loss: 3889.8162\n",
      "Epoch 1258/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 289.4394 - val_loss: 7204.5952\n",
      "Epoch 1259/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 286.2773 - val_loss: 7982.2812\n",
      "Epoch 1260/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 274.8967 - val_loss: 7074.2739\n",
      "Epoch 1261/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 321.9369 - val_loss: 4821.8408\n",
      "Epoch 1262/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 273.8802 - val_loss: 6275.7236\n",
      "Epoch 1263/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 311.7726 - val_loss: 5955.5073\n",
      "Epoch 1264/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 257.2650 - val_loss: 8292.3486\n",
      "Epoch 1265/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 262.1710 - val_loss: 5249.8550\n",
      "Epoch 1266/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 281.0866 - val_loss: 8743.5312\n",
      "Epoch 1267/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 292.9953 - val_loss: 6887.3828\n",
      "Epoch 1268/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 323.5152 - val_loss: 6108.9785\n",
      "Epoch 1269/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 367.4855 - val_loss: 8336.2881\n",
      "Epoch 1270/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 284.5092 - val_loss: 5430.3110\n",
      "Epoch 1271/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 260.8616 - val_loss: 6905.6436\n",
      "Epoch 1272/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 307.0892 - val_loss: 6125.1372\n",
      "Epoch 1273/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 251.1512 - val_loss: 4681.8291\n",
      "Epoch 1274/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 251.6534 - val_loss: 4750.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1275/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 298.1223 - val_loss: 6246.5864\n",
      "Epoch 1276/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 263.7587 - val_loss: 6159.8281\n",
      "Epoch 1277/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 252.0578 - val_loss: 5649.9707\n",
      "Epoch 1278/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 330.6495 - val_loss: 6004.0879\n",
      "Epoch 1279/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 290.2422 - val_loss: 5290.7817\n",
      "Epoch 1280/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 275.8041 - val_loss: 5129.9912\n",
      "Epoch 1281/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 284.9214 - val_loss: 4537.3887\n",
      "Epoch 1282/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 303.4305 - val_loss: 5686.3149\n",
      "Epoch 1283/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 311.1967 - val_loss: 6012.3188\n",
      "Epoch 1284/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 251.4303 - val_loss: 4737.1265\n",
      "Epoch 1285/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 286.7295 - val_loss: 7193.4531\n",
      "Epoch 1286/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 261.9825 - val_loss: 7148.4268\n",
      "Epoch 1287/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 309.0837 - val_loss: 4317.3545\n",
      "Epoch 1288/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 352.8099 - val_loss: 5062.9810\n",
      "Epoch 1289/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 227.3376 - val_loss: 8515.6260\n",
      "Epoch 1290/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 312.4102 - val_loss: 7245.0576\n",
      "Epoch 1291/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 263.6219 - val_loss: 5791.9189\n",
      "Epoch 1292/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 277.2338 - val_loss: 6423.9751\n",
      "Epoch 1293/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.6354 - val_loss: 3603.6548\n",
      "Epoch 1294/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 241.6081 - val_loss: 5781.7935\n",
      "Epoch 1295/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 275.6752 - val_loss: 5557.3379\n",
      "Epoch 1296/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 247.2528 - val_loss: 4687.2275\n",
      "Epoch 1297/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.0888 - val_loss: 7379.2202\n",
      "Epoch 1298/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 284.5007 - val_loss: 6040.9268\n",
      "Epoch 1299/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 262.7362 - val_loss: 4902.0503\n",
      "Epoch 1300/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.7413 - val_loss: 4781.4248\n",
      "Epoch 1301/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 245.9875 - val_loss: 7800.2251\n",
      "Epoch 1302/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.7003 - val_loss: 6424.9419\n",
      "Epoch 1303/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 275.3719 - val_loss: 8550.6738\n",
      "Epoch 1304/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 242.7082 - val_loss: 7041.0488\n",
      "Epoch 1305/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 244.6806 - val_loss: 4933.1328\n",
      "Epoch 1306/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.1471 - val_loss: 5372.8198\n",
      "Epoch 1307/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 274.8725 - val_loss: 6243.2783\n",
      "Epoch 1308/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 234.5314 - val_loss: 5020.9888\n",
      "Epoch 1309/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 286.0653 - val_loss: 7217.8608\n",
      "Epoch 1310/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 252.4858 - val_loss: 5128.3950\n",
      "Epoch 1311/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 304.8138 - val_loss: 8132.2075\n",
      "Epoch 1312/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 279.8354 - val_loss: 6791.9717\n",
      "Epoch 1313/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 285.7278 - val_loss: 4575.2368\n",
      "Epoch 1314/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 290.2370 - val_loss: 5305.0698\n",
      "Epoch 1315/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.2687 - val_loss: 6128.6733\n",
      "Epoch 1316/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 270.9748 - val_loss: 7182.3833\n",
      "Epoch 1317/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 264.5888 - val_loss: 6204.9858\n",
      "Epoch 1318/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 274.9954 - val_loss: 7698.8535\n",
      "Epoch 1319/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 310.1345 - val_loss: 5758.8188\n",
      "Epoch 1320/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 297.3949 - val_loss: 6804.4814\n",
      "Epoch 1321/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 266.0839 - val_loss: 6829.8989\n",
      "Epoch 1322/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.5465 - val_loss: 5243.8125\n",
      "Epoch 1323/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 299.4315 - val_loss: 7170.9995\n",
      "Epoch 1324/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.9461 - val_loss: 6205.4019\n",
      "Epoch 1325/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 251.4507 - val_loss: 6389.4204\n",
      "Epoch 1326/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 277.3159 - val_loss: 5002.3643\n",
      "Epoch 1327/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 235.5282 - val_loss: 7507.1265\n",
      "Epoch 1328/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 280.5582 - val_loss: 4400.5942\n",
      "Epoch 1329/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 300.6756 - val_loss: 6480.1113\n",
      "Epoch 1330/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 255.3709 - val_loss: 5110.7861\n",
      "Epoch 1331/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 261.9026 - val_loss: 4839.7329\n",
      "Epoch 1332/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 251.4605 - val_loss: 4144.5098\n",
      "Epoch 1333/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 284.4485 - val_loss: 6254.5229\n",
      "Epoch 1334/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 292.2190 - val_loss: 5724.1621\n",
      "Epoch 1335/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 298.1349 - val_loss: 6291.8735\n",
      "Epoch 1336/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 283.5220 - val_loss: 4207.0483\n",
      "Epoch 1337/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 263.7669 - val_loss: 6938.7358\n",
      "Epoch 1338/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 258.7162 - val_loss: 7076.5708\n",
      "Epoch 1339/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 273.2647 - val_loss: 5280.0078\n",
      "Epoch 1340/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 262.0849 - val_loss: 4788.4365\n",
      "Epoch 1341/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 226.2961 - val_loss: 7532.6802\n",
      "Epoch 1342/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 270.5408 - val_loss: 7571.9692\n",
      "Epoch 1343/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 306.0580 - val_loss: 6870.0903\n",
      "Epoch 1344/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 266.0906 - val_loss: 6583.8770\n",
      "Epoch 1345/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 272.9494 - val_loss: 8913.8193\n",
      "Epoch 1346/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 257.4883 - val_loss: 7280.2886\n",
      "Epoch 1347/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 261.6449 - val_loss: 4250.7769\n",
      "Epoch 1348/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 297.3004 - val_loss: 6104.2349\n",
      "Epoch 1349/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 286.8258 - val_loss: 6226.4233\n",
      "Epoch 1350/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 248.1486 - val_loss: 6644.3848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1351/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 259.5284 - val_loss: 6614.5435\n",
      "Epoch 1352/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.1868 - val_loss: 7925.7329\n",
      "Epoch 1353/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 303.4363 - val_loss: 5555.7310\n",
      "Epoch 1354/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 231.3228 - val_loss: 6751.1660\n",
      "Epoch 1355/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 245.5452 - val_loss: 5690.3613\n",
      "Epoch 1356/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 282.8373 - val_loss: 4585.7983\n",
      "Epoch 1357/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 291.9279 - val_loss: 7643.8047\n",
      "Epoch 1358/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 270.1179 - val_loss: 7268.7046\n",
      "Epoch 1359/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 250.8314 - val_loss: 6661.6611\n",
      "Epoch 1360/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 241.4500 - val_loss: 3872.9724\n",
      "Epoch 1361/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 305.4130 - val_loss: 4845.3838\n",
      "Epoch 1362/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.4786 - val_loss: 6606.6860\n",
      "Epoch 1363/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 251.7788 - val_loss: 8182.1816\n",
      "Epoch 1364/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 315.2022 - val_loss: 5957.7319\n",
      "Epoch 1365/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 290.9662 - val_loss: 5006.0015\n",
      "Epoch 1366/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.1476 - val_loss: 6731.1982\n",
      "Epoch 1367/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 312.9557 - val_loss: 5331.6323\n",
      "Epoch 1368/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 277.4436 - val_loss: 5096.8682\n",
      "Epoch 1369/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 334.5294 - val_loss: 5720.1753\n",
      "Epoch 1370/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 232.7197 - val_loss: 8473.9404\n",
      "Epoch 1371/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 251.1864 - val_loss: 5590.1748\n",
      "Epoch 1372/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 319.8577 - val_loss: 5007.1919\n",
      "Epoch 1373/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 297.6021 - val_loss: 5636.7754\n",
      "Epoch 1374/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 286.5427 - val_loss: 4523.8047\n",
      "Epoch 1375/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 227.0098 - val_loss: 6258.3970\n",
      "Epoch 1376/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 253.6528 - val_loss: 5992.0127\n",
      "Epoch 1377/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 254.1935 - val_loss: 7222.0254\n",
      "Epoch 1378/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 276.9062 - val_loss: 4595.4380\n",
      "Epoch 1379/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 278.4187 - val_loss: 5533.2310\n",
      "Epoch 1380/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 318.4564 - val_loss: 7430.9253\n",
      "Epoch 1381/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 272.9994 - val_loss: 5194.3730\n",
      "Epoch 1382/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 274.9505 - val_loss: 6059.0093\n",
      "Epoch 1383/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 250.3142 - val_loss: 7331.0371\n",
      "Epoch 1384/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 285.3603 - val_loss: 6503.8735\n",
      "Epoch 1385/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 273.8424 - val_loss: 5048.0405\n",
      "Epoch 1386/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 299.0678 - val_loss: 6916.9531\n",
      "Epoch 1387/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 237.0386 - val_loss: 8033.7158\n",
      "Epoch 1388/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 274.2617 - val_loss: 3793.8843\n",
      "Epoch 1389/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 237.5311 - val_loss: 5717.9980\n",
      "Epoch 1390/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 250.3448 - val_loss: 5059.0176\n",
      "Epoch 1391/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 229.3670 - val_loss: 8327.1875\n",
      "Epoch 1392/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 339.3444 - val_loss: 5894.9771\n",
      "Epoch 1393/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 261.5586 - val_loss: 3733.8228\n",
      "Epoch 1394/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 274.5725 - val_loss: 5672.4058\n",
      "Epoch 1395/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 290.0380 - val_loss: 9585.3643\n",
      "Epoch 1396/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 275.1889 - val_loss: 6219.6089\n",
      "Epoch 1397/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 285.5237 - val_loss: 5650.2090\n",
      "Epoch 1398/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 280.6006 - val_loss: 5095.1465\n",
      "Epoch 1399/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 307.5938 - val_loss: 6450.7661\n",
      "Epoch 1400/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 247.5072 - val_loss: 6283.4121\n",
      "Epoch 1401/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 286.9991 - val_loss: 8219.7285\n",
      "Epoch 1402/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 282.8723 - val_loss: 6340.5200\n",
      "Epoch 1403/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 304.7041 - val_loss: 5443.7231\n",
      "Epoch 1404/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 236.3650 - val_loss: 8111.9292\n",
      "Epoch 1405/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 262.7974 - val_loss: 5452.3540\n",
      "Epoch 1406/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 278.7920 - val_loss: 8242.7539\n",
      "Epoch 1407/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 269.2195 - val_loss: 4771.9160\n",
      "Epoch 1408/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 240.0264 - val_loss: 4502.1753\n",
      "Epoch 1409/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 285.6571 - val_loss: 7650.8765\n",
      "Epoch 1410/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 273.7587 - val_loss: 3834.3713\n",
      "Epoch 1411/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 296.8425 - val_loss: 5001.7910\n",
      "Epoch 1412/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 228.7734 - val_loss: 7757.0981\n",
      "Epoch 1413/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 288.5553 - val_loss: 6556.2202\n",
      "Epoch 1414/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 290.0842 - val_loss: 4848.8594\n",
      "Epoch 1415/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 268.4930 - val_loss: 3602.6162\n",
      "Epoch 1416/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 322.6143 - val_loss: 5205.7891\n",
      "Epoch 1417/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 284.4395 - val_loss: 4789.0215\n",
      "Epoch 1418/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 239.3546 - val_loss: 6762.9985\n",
      "Epoch 1419/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 248.5246 - val_loss: 6827.7231\n",
      "Epoch 1420/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 249.0435 - val_loss: 5535.9575\n",
      "Epoch 1421/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 294.0450 - val_loss: 3755.0576\n",
      "Epoch 1422/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 268.7655 - val_loss: 7304.8579\n",
      "Epoch 1423/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 285.1624 - val_loss: 4487.6138\n",
      "Epoch 1424/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 272.8279 - val_loss: 5482.7437\n",
      "Epoch 1425/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 323.3061 - val_loss: 9161.2939\n",
      "Epoch 1426/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 248.8341 - val_loss: 5441.7749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 232.6836 - val_loss: 6089.5981\n",
      "Epoch 1428/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 257.0654 - val_loss: 5530.6206\n",
      "Epoch 1429/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 274.3621 - val_loss: 6713.1309\n",
      "Epoch 1430/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 256.5160 - val_loss: 6786.3408\n",
      "Epoch 1431/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 331.5673 - val_loss: 8464.2529\n",
      "Epoch 1432/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 285.3932 - val_loss: 3744.3647\n",
      "Epoch 1433/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 286.1482 - val_loss: 6053.4644\n",
      "Epoch 1434/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 254.1630 - val_loss: 4736.1562\n",
      "Epoch 1435/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 238.3149 - val_loss: 7291.8862\n",
      "Epoch 1436/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 261.0203 - val_loss: 7297.6294\n",
      "Epoch 1437/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 259.8256 - val_loss: 6238.6504\n",
      "Epoch 1438/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 308.7551 - val_loss: 5429.2173\n",
      "Epoch 1439/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 266.8530 - val_loss: 5452.5117\n",
      "Epoch 1440/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 250.6341 - val_loss: 4369.3560\n",
      "Epoch 1441/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 285.8534 - val_loss: 5436.8584\n",
      "Epoch 1442/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 239.2345 - val_loss: 5876.9292\n",
      "Epoch 1443/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 331.5524 - val_loss: 8255.4492\n",
      "Epoch 1444/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 317.0537 - val_loss: 5932.8120\n",
      "Epoch 1445/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 287.7013 - val_loss: 5408.6191\n",
      "Epoch 1446/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 245.7297 - val_loss: 8985.4609\n",
      "Epoch 1447/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 255.6653 - val_loss: 4070.5798\n",
      "Epoch 1448/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 242.9478 - val_loss: 5703.7705\n",
      "Epoch 1449/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 285.7901 - val_loss: 6806.1455\n",
      "Epoch 1450/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 248.7423 - val_loss: 7326.5488\n",
      "Epoch 1451/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 305.3777 - val_loss: 3099.6482\n",
      "Epoch 1452/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 284.3674 - val_loss: 4206.8848\n",
      "Epoch 1453/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 312.4332 - val_loss: 7486.8281\n",
      "Epoch 1454/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 277.4575 - val_loss: 6847.0918\n",
      "Epoch 1455/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 253.9493 - val_loss: 8606.1328\n",
      "Epoch 1456/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 282.7330 - val_loss: 3608.6221\n",
      "Epoch 1457/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 258.4965 - val_loss: 6247.4531\n",
      "Epoch 1458/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 275.9199 - val_loss: 6914.6143\n",
      "Epoch 1459/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 266.2291 - val_loss: 6396.8911\n",
      "Epoch 1460/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 266.8833 - val_loss: 6137.4971\n",
      "Epoch 1461/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 278.8101 - val_loss: 6261.1387\n",
      "Epoch 1462/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 298.3320 - val_loss: 7073.2280\n",
      "Epoch 1463/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 257.1778 - val_loss: 5822.6187\n",
      "Epoch 1464/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 333.7146 - val_loss: 6129.7910\n",
      "Epoch 1465/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 280.7696 - val_loss: 6316.6582\n",
      "Epoch 1466/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 267.9190 - val_loss: 6097.1519\n",
      "Epoch 1467/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 252.7906 - val_loss: 5473.8843\n",
      "Epoch 1468/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 284.7530 - val_loss: 6483.3574\n",
      "Epoch 1469/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 249.7713 - val_loss: 4881.5186\n",
      "Epoch 1470/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 262.1479 - val_loss: 6413.9121\n",
      "Epoch 1471/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 251.2813 - val_loss: 7085.8735\n",
      "Epoch 1472/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 276.0255 - val_loss: 8001.8794\n",
      "Epoch 1473/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 299.1723 - val_loss: 7126.5356\n",
      "Epoch 1474/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 309.4156 - val_loss: 4959.2578\n",
      "Epoch 1475/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 292.8065 - val_loss: 5829.9019\n",
      "Epoch 1476/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 295.6649 - val_loss: 5768.8667\n",
      "Epoch 1477/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 265.2990 - val_loss: 5642.5596\n",
      "Epoch 1478/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 274.9708 - val_loss: 9137.9160\n",
      "Epoch 1479/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 294.8150 - val_loss: 4681.7202\n",
      "Epoch 1480/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 300.8693 - val_loss: 6076.9170\n",
      "Epoch 1481/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 276.2027 - val_loss: 6124.9766\n",
      "Epoch 1482/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 283.4633 - val_loss: 7656.6802\n",
      "Epoch 1483/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 263.0408 - val_loss: 6642.5332\n",
      "Epoch 1484/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 282.4858 - val_loss: 7553.2827\n",
      "Epoch 1485/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 254.6130 - val_loss: 6538.0625\n",
      "Epoch 1486/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 252.9839 - val_loss: 6931.4985\n",
      "Epoch 1487/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 295.3029 - val_loss: 5733.1509\n",
      "Epoch 1488/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 323.5783 - val_loss: 4374.2466\n",
      "Epoch 1489/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 272.6308 - val_loss: 6237.3857\n",
      "Epoch 1490/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 249.5300 - val_loss: 4978.7661\n",
      "Epoch 1491/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 269.1783 - val_loss: 4854.9199\n",
      "Epoch 1492/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 267.9077 - val_loss: 4432.4741\n",
      "Epoch 1493/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 232.0972 - val_loss: 7142.2593\n",
      "Epoch 1494/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 236.6148 - val_loss: 4447.1763\n",
      "Epoch 1495/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 281.1550 - val_loss: 5945.2998\n",
      "Epoch 1496/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 289.3046 - val_loss: 7742.5347\n",
      "Epoch 1497/1500\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 262.9148 - val_loss: 8641.2197\n",
      "Epoch 1498/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 286.1838 - val_loss: 5948.1831\n",
      "Epoch 1499/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 256.3341 - val_loss: 4269.8721\n",
      "Epoch 1500/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 267.8428 - val_loss: 6702.2217\n",
      "CPU times: user 5min 5s, sys: 4min 15s, total: 9min 20s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train,y_train,validation_split=0.05,epochs=1500,batch_size=32,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23706dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
